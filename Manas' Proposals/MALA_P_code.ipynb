{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7ff29ae-43cb-4557-8c72-f92582169082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\vinit\\\\Downloads\\\\Research\\\\Quantum-Sampling\\\\Manas' Proposals\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pyscf import gto, scf, fci, lo\n",
    "#import netket as nk; import netket.experimental as nkx\n",
    "import numpy as np\n",
    "import time\n",
    "#import itertools\n",
    "#import qiskit\n",
    "#from qiskit.quantum_info import Pauli, SparsePauliOp\n",
    "from collections import defaultdict\n",
    "#import tensorflow as tf\n",
    "#import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "#import itertools\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "#sys.path.append(os.path.dirname(os.getcwd()) + \"/SAMPLER_LOCAL_IMPORT\")\n",
    "#from Sampling_Quantum import *\n",
    "#from New_MCMC_Proposal import *\n",
    "#sys.path.append(os.getcwd() + \"/Code_download_Bell_2\")\n",
    "from MCMC_funs_Leyden import *\n",
    "\n",
    "#print(qiskit.version.get_version_info())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c16698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61c6d12-f2be-40af-92a7-ef64965dabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_configs(n):\n",
    "    return [np.array(v) for v in product([-1, 1], repeat=n)]\n",
    "\n",
    "\n",
    "\n",
    "def Sampling_MCMC_trajectories(problem_inst, Transition_matrix, sample_size=10000, \n",
    "                               burn=1000, method='Quantum', init_config=None):\n",
    "\n",
    "    n = problem_inst.n\n",
    "    beta = problem_inst.T\n",
    "    prob_dist = np.zeros(2**n)\n",
    "\n",
    "    #exact_dist = np.exp(-beta * Proposal_object.Energy_array)\n",
    "    #exact_dist = exact_dist / np.sum(exact_dist)\n",
    "\n",
    "    #err_hist = []\n",
    "    key_list = []\n",
    "\n",
    "    if init_config==None:\n",
    "        s = np.random.choice([1,-1],size=n)\n",
    "    else: s = init_config\n",
    "\n",
    "    int_key = spinconf2int(s)\n",
    "    #print(int_key)\n",
    "    \n",
    "    for k in range(burn):\n",
    "        #s = Proposal_object.generate_MCMC_trajectories(Transition_matrix, s)\n",
    "         int_key = generate_move(transition_mat=Transition_matrix, state=int_key)\n",
    "\n",
    "    for k in range(sample_size):\n",
    "        #s = Proposal_object.generate_MCMC_trajectories(Transition_matrix, s)\n",
    "        int_key = generate_move(transition_mat=Transition_matrix, state=int_key)\n",
    "        #key = spinconf2int(s)\n",
    "        prob_dist[int_key] +=1\n",
    "        key_list.append(int_key)\n",
    "\n",
    "    \n",
    "    return np.flip(prob_dist/np.sum(prob_dist)), key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9517ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_transition_matrix(T, eps=1e-12, verbose=False):\n",
    "    T = T.copy()\n",
    "    T[T < 0] = 0.0\n",
    "    col_sums = T.sum(axis=0)\n",
    "    bad = np.abs(col_sums) <= eps\n",
    "    good = ~bad\n",
    "    if np.any(good):\n",
    "        T[:, good] /= col_sums[None, good]\n",
    "    if np.any(bad):\n",
    "        T[:, bad] = 1.0 / T.shape[0]\n",
    "        if verbose:\n",
    "            print(f\"{bad.sum()} columns had near-zero sum. Reset to uniform.\")\n",
    "    return T\n",
    "\n",
    "\n",
    "def Cov_computer(sample_vector_stacks):\n",
    "    #sample_vector_stacks is a row-wise stack of last k sample vectors. Each sample vector of length n\n",
    "    X = np.asarray(sample_vector_stacks, dtype=float)\n",
    "    #print(X)\n",
    "    if X.shape[0] <= 1:\n",
    "        return np.eye(X.shape[1])\n",
    "    mean = X.mean(axis=0)\n",
    "    #print(np.tile(mean, (X.shape[0],1)))\n",
    "    diffs = X - np.tile(mean, (X.shape[0],1))\n",
    "    return (diffs.T @ diffs) / (X.shape[0] - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9747c21",
   "metadata": {},
   "source": [
    "## Non-Vectorized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f4b3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U_mala(x, J, h, alpha):\n",
    "    v = np.tanh(alpha * x)\n",
    "    sech_sq = 1.0 * (1 - v ** 2)\n",
    "    return alpha * sech_sq * (h + 2 * J @ v)\n",
    "\n",
    "\n",
    "def normal_dist_logpdf(y, mean, P, epsilon):\n",
    "    diff = y - mean\n",
    "    z = np.linalg.solve(P, diff)          # P z = diff  z = P^-1 diff\n",
    "    quad_form = float(z @ z)\n",
    "    logdet = 2.0*np.sum(np.log(np.diag(P))) + 2.0*y.size*np.log(epsilon)\n",
    "    return -0.5 * (y.size * np.log(2.0 * np.pi) + logdet + (epsilon**(-2))*quad_form)\n",
    "\n",
    "\n",
    "def adaptive_MALA_step_new(x, P, cov, epsilon, problem_inst, alpha=3.0):\n",
    "    J_Q = problem_inst.J_quantum\n",
    "    h_Q = problem_inst.h_quantum\n",
    "\n",
    "    mean_shift_at_xnew = x + (0.5*epsilon**2) * problem_inst.T * cov @ grad_U_mala(x, J_Q, h_Q, alpha)\n",
    "\n",
    "    #white_noise_term = np.random.multivariate_normal(np.zeros(len(x)), epsilon**2 * np.dot(P, np.conjugate(P).T))\n",
    "    x_new = np.random.multivariate_normal(mean=mean_shift_at_xnew, cov=epsilon**2 * np.dot(P, np.conjugate(P).T), size=1)[0]\n",
    "    #print(x_new)\n",
    "\n",
    "    mean_shift_at_xold = x_new + (0.5*epsilon**2) * problem_inst.T * cov @ grad_U_mala(x_new, J_Q, h_Q, alpha)\n",
    "\n",
    "    v_old = np.sign(np.tanh(alpha * x))\n",
    "    v_new = np.sign(np.tanh(alpha * x_new))\n",
    "    E_old = problem_inst.E_arr[::-1][spinconf2int(v_old)]\n",
    "    E_new = problem_inst.E_arr[::-1][spinconf2int(v_new)]\n",
    "\n",
    "    log_prop_dist_fwd = normal_dist_logpdf(x_new, mean_shift_at_xnew, P, epsilon)\n",
    "    log_prop_dist_rev = normal_dist_logpdf(x, mean_shift_at_xold, P, epsilon)\n",
    "\n",
    "    log_accept_ratio = -problem_inst.T * (E_new - E_old) + (log_prop_dist_rev - log_prop_dist_fwd)\n",
    "    accept_prob = min(1.0, np.exp(log_accept_ratio))\n",
    "\n",
    "    if np.random.rand() < accept_prob:\n",
    "        return x_new, v_new\n",
    "    else:\n",
    "        return x, v_old\n",
    "\n",
    "\n",
    "def adaptive_MALA_T_matrix(problem_inst, alpha=3.0, epsilon=0.3, num_samples=500):\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    n = problem_inst.n\n",
    "    #beta = problem_inst.T\n",
    "\n",
    "    configs = all_configs(n)\n",
    "    idx_map = {tuple(c): i for i, c in enumerate(configs)}\n",
    "    T = np.zeros((1 << n, 1 << n))\n",
    "\n",
    "    burn_in = 1000\n",
    "\n",
    "    for v in tqdm(configs, desc=\"Building T matrix\"):\n",
    "        x = np.arctanh(np.clip(v, -0.999, 0.999)) / alpha\n",
    "        cov = np.eye(n)\n",
    "        P = np.eye(n)\n",
    "\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        v_samples = []\n",
    "        x_samples = []\n",
    "        adapt_window = 20\n",
    "\n",
    "        tmg = time.time()\n",
    "\n",
    "        for step in range(1, num_samples+1):\n",
    "            x, v_new = adaptive_MALA_step_new(x, P, cov, epsilon, problem_inst, alpha=3.0)\n",
    "\n",
    "            v_samples.append(v_new)\n",
    "            x_samples.append(x)\n",
    "\n",
    "            key = tuple(v_new.astype(int))\n",
    "            counts[key] = counts.get(key, 0) + 1\n",
    "\n",
    "            if (step) % adapt_window == 0 and step > 200 and step <= burn_in:\n",
    "                if len(x_samples) >= 80:\n",
    "                    #x_hist = np.array([np.arctanh(np.clip(np.tanh(alpha * x0), -0.999, 0.999)) / alpha for x0 in v_samples[-50:]])\n",
    "                    x_hist = [x for x in x_samples[-80:]]\n",
    "\n",
    "                else:\n",
    "                    #x_hist = np.array([np.arctanh(np.clip(np.tanh(alpha * x0), -0.999, 0.999)) / alpha for x0 in v_samples])\n",
    "                    x_hist = [x for x in x_samples[:]]\n",
    "\n",
    "\n",
    "                cov_new = Cov_computer(x_hist)\n",
    "                gamma = 0.1             # diminishing\n",
    "                cov = (1.0 - gamma) * cov_new + gamma * cov\n",
    "                cov = 0.5 * (cov + cov.T)\n",
    "                cov = cov + 1e-5 * np.eye(len(x))\n",
    "                P = np.linalg.cholesky(cov) \n",
    "\n",
    "        i = idx_map[tuple(v)]\n",
    "        total = sum(counts.values())\n",
    "\n",
    "        for v_prime, c in counts.items():\n",
    "            j = idx_map[v_prime]\n",
    "\n",
    "            if j != i :\n",
    "                T[j, i] = c / total\n",
    "\n",
    "        T[i,i] = 1-sum(T[:,i])\n",
    "\n",
    "    T = normalize_transition_matrix(T, eps=1e-12, verbose=True)\n",
    "\n",
    "    return T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f32877",
   "metadata": {},
   "source": [
    "## Vectorized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U_mala_batch(X, J, H, alpha):\n",
    "    V = np.tanh(alpha * X)                      # (B, n)\n",
    "    sech_sq = 1.0 - V**2                        # (B, n)\n",
    "    return alpha * sech_sq * (H[None, :] + 2.0 * V @ J.T)\n",
    "\n",
    "def normal_dist_logpdf_batch(Y, Mean, P, epsilon):\n",
    "    B, n = Y.shape\n",
    "    diff = (Y - Mean)                            # (B, n)\n",
    "\n",
    "    Z = np.linalg.solve(P, diff.T)               # (n, B)\n",
    "    quad = np.sum(Z * Z, axis=0)                 # (B,)\n",
    "\n",
    "    logdet = 2.0 * np.sum(np.log(np.diag(P))) + 2.0 * n * np.log(epsilon)  # scalar\n",
    "    return -0.5 * (n * np.log(2.0 * np.pi) + logdet + (epsilon**(-2)) * quad)\n",
    "\n",
    "def spins_to_index(V):\n",
    "    \"\"\"\n",
    "    V: (B, n) spins in {-1, +1}\n",
    "    Returns (B,) indices \n",
    "    \"\"\"\n",
    "    V = np.asarray(V)\n",
    "    bits = (V < 0).astype(np.int64)                 # +1 -> 0, -1 -> 1\n",
    "    n = V.shape[1]\n",
    "    weights = (1 << np.arange(n-1, -1, -1, dtype=np.int64))  # MSB at column 0\n",
    "    return bits @ weights\n",
    "\n",
    "\n",
    "# ---------- Batched MALA step ----------\n",
    "\n",
    "def adaptive_MALA_step_new_batch(X, P, cov, epsilon, problem_inst, alpha=3.0):\n",
    "    B, n = X.shape\n",
    "    Tinv = problem_inst.T \n",
    "    J_Q = problem_inst.J_quantum\n",
    "    h_Q = problem_inst.h_quantum\n",
    "\n",
    "    grad_X = grad_U_mala_batch(X, J_Q, h_Q, alpha)                 # (B, n)\n",
    "    mean_fwd = X + 0.5 * (epsilon**2) * Tinv * (grad_X @ cov.T)  # (B, n)\n",
    "\n",
    "    # ----- Sample proposal with shared covariance epsilon^2 * P P^T -----\n",
    "    # Draw Z ~ N(0, I), then X_new = mean_fwd + epsilon * Z @ P^T\n",
    "    Z = np.random.randn(B, n)\n",
    "    X_new = mean_fwd + epsilon * (Z @ P.T)                          # (B, n)\n",
    "\n",
    "    grad_Xnew = grad_U_mala_batch(X_new, J_Q, h_Q, alpha)           # (B, n)\n",
    "    mean_rev = X_new + 0.5 * (epsilon**2) * Tinv * (grad_Xnew @ cov.T)\n",
    "\n",
    "    V_old = np.sign(np.tanh(alpha * X))                             # (B, n), in {-1, +1}\n",
    "    V_new = np.sign(np.tanh(alpha * X_new))\n",
    "\n",
    "    idx_old = spins_to_index(V_old)\n",
    "    idx_new = spins_to_index(V_new)\n",
    "    E_table = problem_inst.E_arr[::-1]                    \n",
    "    E_old = E_table[idx_old]                                        \n",
    "    E_new = E_table[idx_new]                                        \n",
    "\n",
    "    log_q_fwd = normal_dist_logpdf_batch(X_new, mean_fwd, P, epsilon)    \n",
    "    log_q_rev = normal_dist_logpdf_batch(X,     mean_rev, P, epsilon)    \n",
    "\n",
    "    log_acc = -Tinv * (E_new - E_old) + (log_q_rev - log_q_fwd)     \n",
    "    acc_prob = np.clip(np.exp(np.minimum(0.0, log_acc)), 0.0, 1.0)  \n",
    "    accept_mask = (np.random.rand(B) < acc_prob)\n",
    "\n",
    "    # Apply accepts with boolean mask\n",
    "    X_next = np.where(accept_mask[:, None], X_new, X)\n",
    "    V_next = np.where(accept_mask[:, None], V_new, V_old)\n",
    "\n",
    "    return X_next, V_next\n",
    "\n",
    "\n",
    "\n",
    "def adaptive_MALA_T_matrix_vec(problem_inst, alpha=3.0, epsilon=0.3, num_samples=500):\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    n = problem_inst.n\n",
    "\n",
    "    V = all_configs(n)\n",
    "    origin_idx = spins_to_index(V)   \n",
    "    #print(origin_idx)\n",
    "\n",
    "    T = np.zeros((1 << n, 1 << n))\n",
    "\n",
    "    burn_in = 1000\n",
    "\n",
    "    X = np.arctanh(np.clip(V, -0.999, 0.999)) / alpha\n",
    "    cov = np.eye(n)\n",
    "    P = np.eye(n)\n",
    "\n",
    "    counts = defaultdict(int)\n",
    "    counts_mat = np.zeros((1<<n, 1<<n), dtype=np.int64)\n",
    "\n",
    "    adapt_window = 20\n",
    "    cov_samples = 20                                  # keep last K samples for covariance computation\n",
    "\n",
    "    # --- rolling buffer of shape (K, B, n) ---\n",
    "    buffer = np.empty((cov_samples, 2**n, n), dtype=float)\n",
    "    buf_idx = 0          # next write position\n",
    "\n",
    "    tmg = time.time()\n",
    "\n",
    "    for step in tqdm(range(1, num_samples+1)):\n",
    "        X, V = adaptive_MALA_step_new_batch(X, P, cov, epsilon, problem_inst, alpha=3.0)\n",
    "        dest_idx = spins_to_index(V)    \n",
    "        #x, v_new = adaptive_MALA_step_new(x, P, cov, epsilon, problem_inst, alpha=3.0)\n",
    "\n",
    "        if step > num_samples // 10:  ## Burn-in for counts_mat\n",
    "            np.add.at(counts_mat, (dest_idx, origin_idx), 1)\n",
    "\n",
    "        buffer[buf_idx] = X\n",
    "        buf_idx = (buf_idx + 1) % cov_samples\n",
    "\n",
    "        # update counts (vectorized)\n",
    "        uniq, cnts = np.unique(V.astype(int), axis=0, return_counts=True)\n",
    "        for row, c in zip(uniq, cnts):\n",
    "            counts[tuple(row.tolist())] = counts.get(tuple(row.tolist()), 0) + int(c)\n",
    "\n",
    "        # adapt covariance on schedule\n",
    "        if (step % adapt_window == 0) and (step > 100) and (step <= burn_in):\n",
    "            X_hist = buffer.reshape(-1, n)                           # ((cov_samples*B), n)\n",
    "            cov_new = Cov_computer(X_hist)\n",
    "            gamma = 0.1\n",
    "            cov = (1.0 - gamma) * cov_new + gamma * cov\n",
    "            cov = 0.5 * (cov + cov.T)\n",
    "            cov += 1e-6 * np.eye(n)                                  # for stability\n",
    "            P = np.linalg.cholesky(cov)\n",
    "\n",
    "    # plt.hist(dest_idx)\n",
    "    # plt.show()\n",
    "\n",
    "    print(\"Total time for config:\", time.time()-tmg)\n",
    "\n",
    "    T = normalize_transition_matrix(np.array(counts_mat, dtype=float), eps=1e-12, verbose=True)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6fc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc36a91-7a55-49db-9870-dd9c8f9e7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "Starting problem instance 8 of 2000 with n = 10\n",
      "Warning: J_Q is not symmetric, correcting...\n",
      "[1023 1022 1021 ...    2    1    0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 137.00it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for config: 7.390126466751099\n",
      "Instance 8, T = 1.0, Proposal = MALA_MC, Acceptance = metropolis, Gap = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinit\\AppData\\Local\\Temp\\ipykernel_24416\\596075925.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results,pd.DataFrame([results_datum])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "instances = pd.read_pickle('instances_new.pkl')\n",
    "tot_instances = np.max(instances['Instance Number'].values)\n",
    "print(tot_instances)\n",
    "#tot_instances = 1\n",
    "results = pd.DataFrame(columns = [\n",
    "    'Instance Number',\n",
    "    'Spins', \n",
    "    'Temperature', \n",
    "    'Connectivity',\n",
    "    'Proposal',\n",
    "    'Acceptance',\n",
    "    'Gap',\n",
    "    'Gap Lazy'\n",
    "        ])\n",
    "T_logmesh = np.logspace(-3, 3, 50)\n",
    "T_round = np.sort( np.kron(np.array([1,5]), 10.**np.arange(-3,4)))\n",
    "T_lim = np.array([0, np.inf]) \n",
    "T_arr = np.unique( np.concatenate((T_logmesh, T_round, T_lim))) \n",
    "#T_arr = np.delete(T_arr, -2) \n",
    "T_arr = [1]\n",
    "delta_step = 0.2\n",
    "\n",
    "for instance_num in range(800, tot_instances+1):\n",
    "    cond  = (instances['Instance Number']==instance_num)\n",
    "    n            = instances[cond]['Spins'].values[0]\n",
    "    connectivity = instances[cond]['Connectivity'].values[0]\n",
    "    J            = instances[cond]['J'].values[0]\n",
    "    h            = instances[cond]['h'].values[0]\n",
    "\n",
    "    print('Starting problem instance', instance_num, 'of', tot_instances, 'with n =', n)\n",
    "\n",
    "    problem_inst = ProblemInstance(J, h)\n",
    "    J_Q = problem_inst.J_quantum\n",
    "    if np.linalg.norm(J_Q - J_Q.T) > 1e-8:\n",
    "        print(\"Warning: J_Q is not symmetric, correcting...\")\n",
    "        problem_inst.J_quantum = (problem_inst.J_quantum + problem_inst.J_quantum.T)  # Ensure symmetry\n",
    "\n",
    "    problem_inst.T = 1.0\n",
    "\n",
    "    proposal_mats = {}\n",
    "\n",
    "    T = 1.0\n",
    "    prop_type = \"MALA_MC\"\n",
    "    accept_type = 'metropolis'\n",
    "\n",
    "\n",
    "    #transition_mat = adaptive_MALA_T_matrix(problem_inst, alpha=3.0, epsilon=0.2, num_samples=1000)\n",
    "    transition_mat = adaptive_MALA_T_matrix_vec(problem_inst, alpha=3.0, epsilon=0.2, num_samples=1000)\n",
    "\n",
    "    gap, _ = abs_spectral_gap(transition_mat)\n",
    "\n",
    "    results_datum = {\n",
    "        'Instance Number': instance_num,\n",
    "        'Spins': n, \n",
    "        'Temperature': T, \n",
    "        'Connectivity': connectivity,\n",
    "        'Proposal': prop_type,\n",
    "        'Acceptance': accept_type,\n",
    "        'Gap': gap,\n",
    "        \"delta_time_step_Trotter\": delta_step\n",
    "    }\n",
    "\n",
    "\n",
    "    results = pd.concat([results,pd.DataFrame([results_datum])], ignore_index=True)\n",
    "\n",
    "    print(\"Instance {}, T = {}, Proposal = {}, Acceptance = {}, Gap = {:.4f}\".format(\n",
    "        instance_num, T, prop_type, accept_type, gap))\n",
    "\n",
    "    #results = pd.concat([results,pd.DataFrame([results_datum])], ignore_index=True)\n",
    "\n",
    "    results_row = pd.DataFrame([results_datum])\n",
    "    results_row.to_csv('results_MALA.csv', mode='a', header=not os.path.exists('results_MALA.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab1f0f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-1, -1, -1, -1, -1, -1, -1, -1, -1, -1): 0,\n",
       " (-1, -1, -1, -1, -1, -1, -1, -1, -1, 1): 1,\n",
       " (-1, -1, -1, -1, -1, -1, -1, -1, 1, -1): 2,\n",
       " (-1, -1, -1, -1, -1, -1, -1, -1, 1, 1): 3,\n",
       " (-1, -1, -1, -1, -1, -1, -1, 1, -1, -1): 4,\n",
       " (-1, -1, -1, -1, -1, -1, -1, 1, -1, 1): 5,\n",
       " (-1, -1, -1, -1, -1, -1, -1, 1, 1, -1): 6,\n",
       " (-1, -1, -1, -1, -1, -1, -1, 1, 1, 1): 7,\n",
       " (-1, -1, -1, -1, -1, -1, 1, -1, -1, -1): 8,\n",
       " (-1, -1, -1, -1, -1, -1, 1, -1, -1, 1): 9,\n",
       " (-1, -1, -1, -1, -1, -1, 1, -1, 1, -1): 10,\n",
       " (-1, -1, -1, -1, -1, -1, 1, -1, 1, 1): 11,\n",
       " (-1, -1, -1, -1, -1, -1, 1, 1, -1, -1): 12,\n",
       " (-1, -1, -1, -1, -1, -1, 1, 1, -1, 1): 13,\n",
       " (-1, -1, -1, -1, -1, -1, 1, 1, 1, -1): 14,\n",
       " (-1, -1, -1, -1, -1, -1, 1, 1, 1, 1): 15,\n",
       " (-1, -1, -1, -1, -1, 1, -1, -1, -1, -1): 16,\n",
       " (-1, -1, -1, -1, -1, 1, -1, -1, -1, 1): 17,\n",
       " (-1, -1, -1, -1, -1, 1, -1, -1, 1, -1): 18,\n",
       " (-1, -1, -1, -1, -1, 1, -1, -1, 1, 1): 19,\n",
       " (-1, -1, -1, -1, -1, 1, -1, 1, -1, -1): 20,\n",
       " (-1, -1, -1, -1, -1, 1, -1, 1, -1, 1): 21,\n",
       " (-1, -1, -1, -1, -1, 1, -1, 1, 1, -1): 22,\n",
       " (-1, -1, -1, -1, -1, 1, -1, 1, 1, 1): 23,\n",
       " (-1, -1, -1, -1, -1, 1, 1, -1, -1, -1): 24,\n",
       " (-1, -1, -1, -1, -1, 1, 1, -1, -1, 1): 25,\n",
       " (-1, -1, -1, -1, -1, 1, 1, -1, 1, -1): 26,\n",
       " (-1, -1, -1, -1, -1, 1, 1, -1, 1, 1): 27,\n",
       " (-1, -1, -1, -1, -1, 1, 1, 1, -1, -1): 28,\n",
       " (-1, -1, -1, -1, -1, 1, 1, 1, -1, 1): 29,\n",
       " (-1, -1, -1, -1, -1, 1, 1, 1, 1, -1): 30,\n",
       " (-1, -1, -1, -1, -1, 1, 1, 1, 1, 1): 31,\n",
       " (-1, -1, -1, -1, 1, -1, -1, -1, -1, -1): 32,\n",
       " (-1, -1, -1, -1, 1, -1, -1, -1, -1, 1): 33,\n",
       " (-1, -1, -1, -1, 1, -1, -1, -1, 1, -1): 34,\n",
       " (-1, -1, -1, -1, 1, -1, -1, -1, 1, 1): 35,\n",
       " (-1, -1, -1, -1, 1, -1, -1, 1, -1, -1): 36,\n",
       " (-1, -1, -1, -1, 1, -1, -1, 1, -1, 1): 37,\n",
       " (-1, -1, -1, -1, 1, -1, -1, 1, 1, -1): 38,\n",
       " (-1, -1, -1, -1, 1, -1, -1, 1, 1, 1): 39,\n",
       " (-1, -1, -1, -1, 1, -1, 1, -1, -1, -1): 40,\n",
       " (-1, -1, -1, -1, 1, -1, 1, -1, -1, 1): 41,\n",
       " (-1, -1, -1, -1, 1, -1, 1, -1, 1, -1): 42,\n",
       " (-1, -1, -1, -1, 1, -1, 1, -1, 1, 1): 43,\n",
       " (-1, -1, -1, -1, 1, -1, 1, 1, -1, -1): 44,\n",
       " (-1, -1, -1, -1, 1, -1, 1, 1, -1, 1): 45,\n",
       " (-1, -1, -1, -1, 1, -1, 1, 1, 1, -1): 46,\n",
       " (-1, -1, -1, -1, 1, -1, 1, 1, 1, 1): 47,\n",
       " (-1, -1, -1, -1, 1, 1, -1, -1, -1, -1): 48,\n",
       " (-1, -1, -1, -1, 1, 1, -1, -1, -1, 1): 49,\n",
       " (-1, -1, -1, -1, 1, 1, -1, -1, 1, -1): 50,\n",
       " (-1, -1, -1, -1, 1, 1, -1, -1, 1, 1): 51,\n",
       " (-1, -1, -1, -1, 1, 1, -1, 1, -1, -1): 52,\n",
       " (-1, -1, -1, -1, 1, 1, -1, 1, -1, 1): 53,\n",
       " (-1, -1, -1, -1, 1, 1, -1, 1, 1, -1): 54,\n",
       " (-1, -1, -1, -1, 1, 1, -1, 1, 1, 1): 55,\n",
       " (-1, -1, -1, -1, 1, 1, 1, -1, -1, -1): 56,\n",
       " (-1, -1, -1, -1, 1, 1, 1, -1, -1, 1): 57,\n",
       " (-1, -1, -1, -1, 1, 1, 1, -1, 1, -1): 58,\n",
       " (-1, -1, -1, -1, 1, 1, 1, -1, 1, 1): 59,\n",
       " (-1, -1, -1, -1, 1, 1, 1, 1, -1, -1): 60,\n",
       " (-1, -1, -1, -1, 1, 1, 1, 1, -1, 1): 61,\n",
       " (-1, -1, -1, -1, 1, 1, 1, 1, 1, -1): 62,\n",
       " (-1, -1, -1, -1, 1, 1, 1, 1, 1, 1): 63,\n",
       " (-1, -1, -1, 1, -1, -1, -1, -1, -1, -1): 64,\n",
       " (-1, -1, -1, 1, -1, -1, -1, -1, -1, 1): 65,\n",
       " (-1, -1, -1, 1, -1, -1, -1, -1, 1, -1): 66,\n",
       " (-1, -1, -1, 1, -1, -1, -1, -1, 1, 1): 67,\n",
       " (-1, -1, -1, 1, -1, -1, -1, 1, -1, -1): 68,\n",
       " (-1, -1, -1, 1, -1, -1, -1, 1, -1, 1): 69,\n",
       " (-1, -1, -1, 1, -1, -1, -1, 1, 1, -1): 70,\n",
       " (-1, -1, -1, 1, -1, -1, -1, 1, 1, 1): 71,\n",
       " (-1, -1, -1, 1, -1, -1, 1, -1, -1, -1): 72,\n",
       " (-1, -1, -1, 1, -1, -1, 1, -1, -1, 1): 73,\n",
       " (-1, -1, -1, 1, -1, -1, 1, -1, 1, -1): 74,\n",
       " (-1, -1, -1, 1, -1, -1, 1, -1, 1, 1): 75,\n",
       " (-1, -1, -1, 1, -1, -1, 1, 1, -1, -1): 76,\n",
       " (-1, -1, -1, 1, -1, -1, 1, 1, -1, 1): 77,\n",
       " (-1, -1, -1, 1, -1, -1, 1, 1, 1, -1): 78,\n",
       " (-1, -1, -1, 1, -1, -1, 1, 1, 1, 1): 79,\n",
       " (-1, -1, -1, 1, -1, 1, -1, -1, -1, -1): 80,\n",
       " (-1, -1, -1, 1, -1, 1, -1, -1, -1, 1): 81,\n",
       " (-1, -1, -1, 1, -1, 1, -1, -1, 1, -1): 82,\n",
       " (-1, -1, -1, 1, -1, 1, -1, -1, 1, 1): 83,\n",
       " (-1, -1, -1, 1, -1, 1, -1, 1, -1, -1): 84,\n",
       " (-1, -1, -1, 1, -1, 1, -1, 1, -1, 1): 85,\n",
       " (-1, -1, -1, 1, -1, 1, -1, 1, 1, -1): 86,\n",
       " (-1, -1, -1, 1, -1, 1, -1, 1, 1, 1): 87,\n",
       " (-1, -1, -1, 1, -1, 1, 1, -1, -1, -1): 88,\n",
       " (-1, -1, -1, 1, -1, 1, 1, -1, -1, 1): 89,\n",
       " (-1, -1, -1, 1, -1, 1, 1, -1, 1, -1): 90,\n",
       " (-1, -1, -1, 1, -1, 1, 1, -1, 1, 1): 91,\n",
       " (-1, -1, -1, 1, -1, 1, 1, 1, -1, -1): 92,\n",
       " (-1, -1, -1, 1, -1, 1, 1, 1, -1, 1): 93,\n",
       " (-1, -1, -1, 1, -1, 1, 1, 1, 1, -1): 94,\n",
       " (-1, -1, -1, 1, -1, 1, 1, 1, 1, 1): 95,\n",
       " (-1, -1, -1, 1, 1, -1, -1, -1, -1, -1): 96,\n",
       " (-1, -1, -1, 1, 1, -1, -1, -1, -1, 1): 97,\n",
       " (-1, -1, -1, 1, 1, -1, -1, -1, 1, -1): 98,\n",
       " (-1, -1, -1, 1, 1, -1, -1, -1, 1, 1): 99,\n",
       " (-1, -1, -1, 1, 1, -1, -1, 1, -1, -1): 100,\n",
       " (-1, -1, -1, 1, 1, -1, -1, 1, -1, 1): 101,\n",
       " (-1, -1, -1, 1, 1, -1, -1, 1, 1, -1): 102,\n",
       " (-1, -1, -1, 1, 1, -1, -1, 1, 1, 1): 103,\n",
       " (-1, -1, -1, 1, 1, -1, 1, -1, -1, -1): 104,\n",
       " (-1, -1, -1, 1, 1, -1, 1, -1, -1, 1): 105,\n",
       " (-1, -1, -1, 1, 1, -1, 1, -1, 1, -1): 106,\n",
       " (-1, -1, -1, 1, 1, -1, 1, -1, 1, 1): 107,\n",
       " (-1, -1, -1, 1, 1, -1, 1, 1, -1, -1): 108,\n",
       " (-1, -1, -1, 1, 1, -1, 1, 1, -1, 1): 109,\n",
       " (-1, -1, -1, 1, 1, -1, 1, 1, 1, -1): 110,\n",
       " (-1, -1, -1, 1, 1, -1, 1, 1, 1, 1): 111,\n",
       " (-1, -1, -1, 1, 1, 1, -1, -1, -1, -1): 112,\n",
       " (-1, -1, -1, 1, 1, 1, -1, -1, -1, 1): 113,\n",
       " (-1, -1, -1, 1, 1, 1, -1, -1, 1, -1): 114,\n",
       " (-1, -1, -1, 1, 1, 1, -1, -1, 1, 1): 115,\n",
       " (-1, -1, -1, 1, 1, 1, -1, 1, -1, -1): 116,\n",
       " (-1, -1, -1, 1, 1, 1, -1, 1, -1, 1): 117,\n",
       " (-1, -1, -1, 1, 1, 1, -1, 1, 1, -1): 118,\n",
       " (-1, -1, -1, 1, 1, 1, -1, 1, 1, 1): 119,\n",
       " (-1, -1, -1, 1, 1, 1, 1, -1, -1, -1): 120,\n",
       " (-1, -1, -1, 1, 1, 1, 1, -1, -1, 1): 121,\n",
       " (-1, -1, -1, 1, 1, 1, 1, -1, 1, -1): 122,\n",
       " (-1, -1, -1, 1, 1, 1, 1, -1, 1, 1): 123,\n",
       " (-1, -1, -1, 1, 1, 1, 1, 1, -1, -1): 124,\n",
       " (-1, -1, -1, 1, 1, 1, 1, 1, -1, 1): 125,\n",
       " (-1, -1, -1, 1, 1, 1, 1, 1, 1, -1): 126,\n",
       " (-1, -1, -1, 1, 1, 1, 1, 1, 1, 1): 127,\n",
       " (-1, -1, 1, -1, -1, -1, -1, -1, -1, -1): 128,\n",
       " (-1, -1, 1, -1, -1, -1, -1, -1, -1, 1): 129,\n",
       " (-1, -1, 1, -1, -1, -1, -1, -1, 1, -1): 130,\n",
       " (-1, -1, 1, -1, -1, -1, -1, -1, 1, 1): 131,\n",
       " (-1, -1, 1, -1, -1, -1, -1, 1, -1, -1): 132,\n",
       " (-1, -1, 1, -1, -1, -1, -1, 1, -1, 1): 133,\n",
       " (-1, -1, 1, -1, -1, -1, -1, 1, 1, -1): 134,\n",
       " (-1, -1, 1, -1, -1, -1, -1, 1, 1, 1): 135,\n",
       " (-1, -1, 1, -1, -1, -1, 1, -1, -1, -1): 136,\n",
       " (-1, -1, 1, -1, -1, -1, 1, -1, -1, 1): 137,\n",
       " (-1, -1, 1, -1, -1, -1, 1, -1, 1, -1): 138,\n",
       " (-1, -1, 1, -1, -1, -1, 1, -1, 1, 1): 139,\n",
       " (-1, -1, 1, -1, -1, -1, 1, 1, -1, -1): 140,\n",
       " (-1, -1, 1, -1, -1, -1, 1, 1, -1, 1): 141,\n",
       " (-1, -1, 1, -1, -1, -1, 1, 1, 1, -1): 142,\n",
       " (-1, -1, 1, -1, -1, -1, 1, 1, 1, 1): 143,\n",
       " (-1, -1, 1, -1, -1, 1, -1, -1, -1, -1): 144,\n",
       " (-1, -1, 1, -1, -1, 1, -1, -1, -1, 1): 145,\n",
       " (-1, -1, 1, -1, -1, 1, -1, -1, 1, -1): 146,\n",
       " (-1, -1, 1, -1, -1, 1, -1, -1, 1, 1): 147,\n",
       " (-1, -1, 1, -1, -1, 1, -1, 1, -1, -1): 148,\n",
       " (-1, -1, 1, -1, -1, 1, -1, 1, -1, 1): 149,\n",
       " (-1, -1, 1, -1, -1, 1, -1, 1, 1, -1): 150,\n",
       " (-1, -1, 1, -1, -1, 1, -1, 1, 1, 1): 151,\n",
       " (-1, -1, 1, -1, -1, 1, 1, -1, -1, -1): 152,\n",
       " (-1, -1, 1, -1, -1, 1, 1, -1, -1, 1): 153,\n",
       " (-1, -1, 1, -1, -1, 1, 1, -1, 1, -1): 154,\n",
       " (-1, -1, 1, -1, -1, 1, 1, -1, 1, 1): 155,\n",
       " (-1, -1, 1, -1, -1, 1, 1, 1, -1, -1): 156,\n",
       " (-1, -1, 1, -1, -1, 1, 1, 1, -1, 1): 157,\n",
       " (-1, -1, 1, -1, -1, 1, 1, 1, 1, -1): 158,\n",
       " (-1, -1, 1, -1, -1, 1, 1, 1, 1, 1): 159,\n",
       " (-1, -1, 1, -1, 1, -1, -1, -1, -1, -1): 160,\n",
       " (-1, -1, 1, -1, 1, -1, -1, -1, -1, 1): 161,\n",
       " (-1, -1, 1, -1, 1, -1, -1, -1, 1, -1): 162,\n",
       " (-1, -1, 1, -1, 1, -1, -1, -1, 1, 1): 163,\n",
       " (-1, -1, 1, -1, 1, -1, -1, 1, -1, -1): 164,\n",
       " (-1, -1, 1, -1, 1, -1, -1, 1, -1, 1): 165,\n",
       " (-1, -1, 1, -1, 1, -1, -1, 1, 1, -1): 166,\n",
       " (-1, -1, 1, -1, 1, -1, -1, 1, 1, 1): 167,\n",
       " (-1, -1, 1, -1, 1, -1, 1, -1, -1, -1): 168,\n",
       " (-1, -1, 1, -1, 1, -1, 1, -1, -1, 1): 169,\n",
       " (-1, -1, 1, -1, 1, -1, 1, -1, 1, -1): 170,\n",
       " (-1, -1, 1, -1, 1, -1, 1, -1, 1, 1): 171,\n",
       " (-1, -1, 1, -1, 1, -1, 1, 1, -1, -1): 172,\n",
       " (-1, -1, 1, -1, 1, -1, 1, 1, -1, 1): 173,\n",
       " (-1, -1, 1, -1, 1, -1, 1, 1, 1, -1): 174,\n",
       " (-1, -1, 1, -1, 1, -1, 1, 1, 1, 1): 175,\n",
       " (-1, -1, 1, -1, 1, 1, -1, -1, -1, -1): 176,\n",
       " (-1, -1, 1, -1, 1, 1, -1, -1, -1, 1): 177,\n",
       " (-1, -1, 1, -1, 1, 1, -1, -1, 1, -1): 178,\n",
       " (-1, -1, 1, -1, 1, 1, -1, -1, 1, 1): 179,\n",
       " (-1, -1, 1, -1, 1, 1, -1, 1, -1, -1): 180,\n",
       " (-1, -1, 1, -1, 1, 1, -1, 1, -1, 1): 181,\n",
       " (-1, -1, 1, -1, 1, 1, -1, 1, 1, -1): 182,\n",
       " (-1, -1, 1, -1, 1, 1, -1, 1, 1, 1): 183,\n",
       " (-1, -1, 1, -1, 1, 1, 1, -1, -1, -1): 184,\n",
       " (-1, -1, 1, -1, 1, 1, 1, -1, -1, 1): 185,\n",
       " (-1, -1, 1, -1, 1, 1, 1, -1, 1, -1): 186,\n",
       " (-1, -1, 1, -1, 1, 1, 1, -1, 1, 1): 187,\n",
       " (-1, -1, 1, -1, 1, 1, 1, 1, -1, -1): 188,\n",
       " (-1, -1, 1, -1, 1, 1, 1, 1, -1, 1): 189,\n",
       " (-1, -1, 1, -1, 1, 1, 1, 1, 1, -1): 190,\n",
       " (-1, -1, 1, -1, 1, 1, 1, 1, 1, 1): 191,\n",
       " (-1, -1, 1, 1, -1, -1, -1, -1, -1, -1): 192,\n",
       " (-1, -1, 1, 1, -1, -1, -1, -1, -1, 1): 193,\n",
       " (-1, -1, 1, 1, -1, -1, -1, -1, 1, -1): 194,\n",
       " (-1, -1, 1, 1, -1, -1, -1, -1, 1, 1): 195,\n",
       " (-1, -1, 1, 1, -1, -1, -1, 1, -1, -1): 196,\n",
       " (-1, -1, 1, 1, -1, -1, -1, 1, -1, 1): 197,\n",
       " (-1, -1, 1, 1, -1, -1, -1, 1, 1, -1): 198,\n",
       " (-1, -1, 1, 1, -1, -1, -1, 1, 1, 1): 199,\n",
       " (-1, -1, 1, 1, -1, -1, 1, -1, -1, -1): 200,\n",
       " (-1, -1, 1, 1, -1, -1, 1, -1, -1, 1): 201,\n",
       " (-1, -1, 1, 1, -1, -1, 1, -1, 1, -1): 202,\n",
       " (-1, -1, 1, 1, -1, -1, 1, -1, 1, 1): 203,\n",
       " (-1, -1, 1, 1, -1, -1, 1, 1, -1, -1): 204,\n",
       " (-1, -1, 1, 1, -1, -1, 1, 1, -1, 1): 205,\n",
       " (-1, -1, 1, 1, -1, -1, 1, 1, 1, -1): 206,\n",
       " (-1, -1, 1, 1, -1, -1, 1, 1, 1, 1): 207,\n",
       " (-1, -1, 1, 1, -1, 1, -1, -1, -1, -1): 208,\n",
       " (-1, -1, 1, 1, -1, 1, -1, -1, -1, 1): 209,\n",
       " (-1, -1, 1, 1, -1, 1, -1, -1, 1, -1): 210,\n",
       " (-1, -1, 1, 1, -1, 1, -1, -1, 1, 1): 211,\n",
       " (-1, -1, 1, 1, -1, 1, -1, 1, -1, -1): 212,\n",
       " (-1, -1, 1, 1, -1, 1, -1, 1, -1, 1): 213,\n",
       " (-1, -1, 1, 1, -1, 1, -1, 1, 1, -1): 214,\n",
       " (-1, -1, 1, 1, -1, 1, -1, 1, 1, 1): 215,\n",
       " (-1, -1, 1, 1, -1, 1, 1, -1, -1, -1): 216,\n",
       " (-1, -1, 1, 1, -1, 1, 1, -1, -1, 1): 217,\n",
       " (-1, -1, 1, 1, -1, 1, 1, -1, 1, -1): 218,\n",
       " (-1, -1, 1, 1, -1, 1, 1, -1, 1, 1): 219,\n",
       " (-1, -1, 1, 1, -1, 1, 1, 1, -1, -1): 220,\n",
       " (-1, -1, 1, 1, -1, 1, 1, 1, -1, 1): 221,\n",
       " (-1, -1, 1, 1, -1, 1, 1, 1, 1, -1): 222,\n",
       " (-1, -1, 1, 1, -1, 1, 1, 1, 1, 1): 223,\n",
       " (-1, -1, 1, 1, 1, -1, -1, -1, -1, -1): 224,\n",
       " (-1, -1, 1, 1, 1, -1, -1, -1, -1, 1): 225,\n",
       " (-1, -1, 1, 1, 1, -1, -1, -1, 1, -1): 226,\n",
       " (-1, -1, 1, 1, 1, -1, -1, -1, 1, 1): 227,\n",
       " (-1, -1, 1, 1, 1, -1, -1, 1, -1, -1): 228,\n",
       " (-1, -1, 1, 1, 1, -1, -1, 1, -1, 1): 229,\n",
       " (-1, -1, 1, 1, 1, -1, -1, 1, 1, -1): 230,\n",
       " (-1, -1, 1, 1, 1, -1, -1, 1, 1, 1): 231,\n",
       " (-1, -1, 1, 1, 1, -1, 1, -1, -1, -1): 232,\n",
       " (-1, -1, 1, 1, 1, -1, 1, -1, -1, 1): 233,\n",
       " (-1, -1, 1, 1, 1, -1, 1, -1, 1, -1): 234,\n",
       " (-1, -1, 1, 1, 1, -1, 1, -1, 1, 1): 235,\n",
       " (-1, -1, 1, 1, 1, -1, 1, 1, -1, -1): 236,\n",
       " (-1, -1, 1, 1, 1, -1, 1, 1, -1, 1): 237,\n",
       " (-1, -1, 1, 1, 1, -1, 1, 1, 1, -1): 238,\n",
       " (-1, -1, 1, 1, 1, -1, 1, 1, 1, 1): 239,\n",
       " (-1, -1, 1, 1, 1, 1, -1, -1, -1, -1): 240,\n",
       " (-1, -1, 1, 1, 1, 1, -1, -1, -1, 1): 241,\n",
       " (-1, -1, 1, 1, 1, 1, -1, -1, 1, -1): 242,\n",
       " (-1, -1, 1, 1, 1, 1, -1, -1, 1, 1): 243,\n",
       " (-1, -1, 1, 1, 1, 1, -1, 1, -1, -1): 244,\n",
       " (-1, -1, 1, 1, 1, 1, -1, 1, -1, 1): 245,\n",
       " (-1, -1, 1, 1, 1, 1, -1, 1, 1, -1): 246,\n",
       " (-1, -1, 1, 1, 1, 1, -1, 1, 1, 1): 247,\n",
       " (-1, -1, 1, 1, 1, 1, 1, -1, -1, -1): 248,\n",
       " (-1, -1, 1, 1, 1, 1, 1, -1, -1, 1): 249,\n",
       " (-1, -1, 1, 1, 1, 1, 1, -1, 1, -1): 250,\n",
       " (-1, -1, 1, 1, 1, 1, 1, -1, 1, 1): 251,\n",
       " (-1, -1, 1, 1, 1, 1, 1, 1, -1, -1): 252,\n",
       " (-1, -1, 1, 1, 1, 1, 1, 1, -1, 1): 253,\n",
       " (-1, -1, 1, 1, 1, 1, 1, 1, 1, -1): 254,\n",
       " (-1, -1, 1, 1, 1, 1, 1, 1, 1, 1): 255,\n",
       " (-1, 1, -1, -1, -1, -1, -1, -1, -1, -1): 256,\n",
       " (-1, 1, -1, -1, -1, -1, -1, -1, -1, 1): 257,\n",
       " (-1, 1, -1, -1, -1, -1, -1, -1, 1, -1): 258,\n",
       " (-1, 1, -1, -1, -1, -1, -1, -1, 1, 1): 259,\n",
       " (-1, 1, -1, -1, -1, -1, -1, 1, -1, -1): 260,\n",
       " (-1, 1, -1, -1, -1, -1, -1, 1, -1, 1): 261,\n",
       " (-1, 1, -1, -1, -1, -1, -1, 1, 1, -1): 262,\n",
       " (-1, 1, -1, -1, -1, -1, -1, 1, 1, 1): 263,\n",
       " (-1, 1, -1, -1, -1, -1, 1, -1, -1, -1): 264,\n",
       " (-1, 1, -1, -1, -1, -1, 1, -1, -1, 1): 265,\n",
       " (-1, 1, -1, -1, -1, -1, 1, -1, 1, -1): 266,\n",
       " (-1, 1, -1, -1, -1, -1, 1, -1, 1, 1): 267,\n",
       " (-1, 1, -1, -1, -1, -1, 1, 1, -1, -1): 268,\n",
       " (-1, 1, -1, -1, -1, -1, 1, 1, -1, 1): 269,\n",
       " (-1, 1, -1, -1, -1, -1, 1, 1, 1, -1): 270,\n",
       " (-1, 1, -1, -1, -1, -1, 1, 1, 1, 1): 271,\n",
       " (-1, 1, -1, -1, -1, 1, -1, -1, -1, -1): 272,\n",
       " (-1, 1, -1, -1, -1, 1, -1, -1, -1, 1): 273,\n",
       " (-1, 1, -1, -1, -1, 1, -1, -1, 1, -1): 274,\n",
       " (-1, 1, -1, -1, -1, 1, -1, -1, 1, 1): 275,\n",
       " (-1, 1, -1, -1, -1, 1, -1, 1, -1, -1): 276,\n",
       " (-1, 1, -1, -1, -1, 1, -1, 1, -1, 1): 277,\n",
       " (-1, 1, -1, -1, -1, 1, -1, 1, 1, -1): 278,\n",
       " (-1, 1, -1, -1, -1, 1, -1, 1, 1, 1): 279,\n",
       " (-1, 1, -1, -1, -1, 1, 1, -1, -1, -1): 280,\n",
       " (-1, 1, -1, -1, -1, 1, 1, -1, -1, 1): 281,\n",
       " (-1, 1, -1, -1, -1, 1, 1, -1, 1, -1): 282,\n",
       " (-1, 1, -1, -1, -1, 1, 1, -1, 1, 1): 283,\n",
       " (-1, 1, -1, -1, -1, 1, 1, 1, -1, -1): 284,\n",
       " (-1, 1, -1, -1, -1, 1, 1, 1, -1, 1): 285,\n",
       " (-1, 1, -1, -1, -1, 1, 1, 1, 1, -1): 286,\n",
       " (-1, 1, -1, -1, -1, 1, 1, 1, 1, 1): 287,\n",
       " (-1, 1, -1, -1, 1, -1, -1, -1, -1, -1): 288,\n",
       " (-1, 1, -1, -1, 1, -1, -1, -1, -1, 1): 289,\n",
       " (-1, 1, -1, -1, 1, -1, -1, -1, 1, -1): 290,\n",
       " (-1, 1, -1, -1, 1, -1, -1, -1, 1, 1): 291,\n",
       " (-1, 1, -1, -1, 1, -1, -1, 1, -1, -1): 292,\n",
       " (-1, 1, -1, -1, 1, -1, -1, 1, -1, 1): 293,\n",
       " (-1, 1, -1, -1, 1, -1, -1, 1, 1, -1): 294,\n",
       " (-1, 1, -1, -1, 1, -1, -1, 1, 1, 1): 295,\n",
       " (-1, 1, -1, -1, 1, -1, 1, -1, -1, -1): 296,\n",
       " (-1, 1, -1, -1, 1, -1, 1, -1, -1, 1): 297,\n",
       " (-1, 1, -1, -1, 1, -1, 1, -1, 1, -1): 298,\n",
       " (-1, 1, -1, -1, 1, -1, 1, -1, 1, 1): 299,\n",
       " (-1, 1, -1, -1, 1, -1, 1, 1, -1, -1): 300,\n",
       " (-1, 1, -1, -1, 1, -1, 1, 1, -1, 1): 301,\n",
       " (-1, 1, -1, -1, 1, -1, 1, 1, 1, -1): 302,\n",
       " (-1, 1, -1, -1, 1, -1, 1, 1, 1, 1): 303,\n",
       " (-1, 1, -1, -1, 1, 1, -1, -1, -1, -1): 304,\n",
       " (-1, 1, -1, -1, 1, 1, -1, -1, -1, 1): 305,\n",
       " (-1, 1, -1, -1, 1, 1, -1, -1, 1, -1): 306,\n",
       " (-1, 1, -1, -1, 1, 1, -1, -1, 1, 1): 307,\n",
       " (-1, 1, -1, -1, 1, 1, -1, 1, -1, -1): 308,\n",
       " (-1, 1, -1, -1, 1, 1, -1, 1, -1, 1): 309,\n",
       " (-1, 1, -1, -1, 1, 1, -1, 1, 1, -1): 310,\n",
       " (-1, 1, -1, -1, 1, 1, -1, 1, 1, 1): 311,\n",
       " (-1, 1, -1, -1, 1, 1, 1, -1, -1, -1): 312,\n",
       " (-1, 1, -1, -1, 1, 1, 1, -1, -1, 1): 313,\n",
       " (-1, 1, -1, -1, 1, 1, 1, -1, 1, -1): 314,\n",
       " (-1, 1, -1, -1, 1, 1, 1, -1, 1, 1): 315,\n",
       " (-1, 1, -1, -1, 1, 1, 1, 1, -1, -1): 316,\n",
       " (-1, 1, -1, -1, 1, 1, 1, 1, -1, 1): 317,\n",
       " (-1, 1, -1, -1, 1, 1, 1, 1, 1, -1): 318,\n",
       " (-1, 1, -1, -1, 1, 1, 1, 1, 1, 1): 319,\n",
       " (-1, 1, -1, 1, -1, -1, -1, -1, -1, -1): 320,\n",
       " (-1, 1, -1, 1, -1, -1, -1, -1, -1, 1): 321,\n",
       " (-1, 1, -1, 1, -1, -1, -1, -1, 1, -1): 322,\n",
       " (-1, 1, -1, 1, -1, -1, -1, -1, 1, 1): 323,\n",
       " (-1, 1, -1, 1, -1, -1, -1, 1, -1, -1): 324,\n",
       " (-1, 1, -1, 1, -1, -1, -1, 1, -1, 1): 325,\n",
       " (-1, 1, -1, 1, -1, -1, -1, 1, 1, -1): 326,\n",
       " (-1, 1, -1, 1, -1, -1, -1, 1, 1, 1): 327,\n",
       " (-1, 1, -1, 1, -1, -1, 1, -1, -1, -1): 328,\n",
       " (-1, 1, -1, 1, -1, -1, 1, -1, -1, 1): 329,\n",
       " (-1, 1, -1, 1, -1, -1, 1, -1, 1, -1): 330,\n",
       " (-1, 1, -1, 1, -1, -1, 1, -1, 1, 1): 331,\n",
       " (-1, 1, -1, 1, -1, -1, 1, 1, -1, -1): 332,\n",
       " (-1, 1, -1, 1, -1, -1, 1, 1, -1, 1): 333,\n",
       " (-1, 1, -1, 1, -1, -1, 1, 1, 1, -1): 334,\n",
       " (-1, 1, -1, 1, -1, -1, 1, 1, 1, 1): 335,\n",
       " (-1, 1, -1, 1, -1, 1, -1, -1, -1, -1): 336,\n",
       " (-1, 1, -1, 1, -1, 1, -1, -1, -1, 1): 337,\n",
       " (-1, 1, -1, 1, -1, 1, -1, -1, 1, -1): 338,\n",
       " (-1, 1, -1, 1, -1, 1, -1, -1, 1, 1): 339,\n",
       " (-1, 1, -1, 1, -1, 1, -1, 1, -1, -1): 340,\n",
       " (-1, 1, -1, 1, -1, 1, -1, 1, -1, 1): 341,\n",
       " (-1, 1, -1, 1, -1, 1, -1, 1, 1, -1): 342,\n",
       " (-1, 1, -1, 1, -1, 1, -1, 1, 1, 1): 343,\n",
       " (-1, 1, -1, 1, -1, 1, 1, -1, -1, -1): 344,\n",
       " (-1, 1, -1, 1, -1, 1, 1, -1, -1, 1): 345,\n",
       " (-1, 1, -1, 1, -1, 1, 1, -1, 1, -1): 346,\n",
       " (-1, 1, -1, 1, -1, 1, 1, -1, 1, 1): 347,\n",
       " (-1, 1, -1, 1, -1, 1, 1, 1, -1, -1): 348,\n",
       " (-1, 1, -1, 1, -1, 1, 1, 1, -1, 1): 349,\n",
       " (-1, 1, -1, 1, -1, 1, 1, 1, 1, -1): 350,\n",
       " (-1, 1, -1, 1, -1, 1, 1, 1, 1, 1): 351,\n",
       " (-1, 1, -1, 1, 1, -1, -1, -1, -1, -1): 352,\n",
       " (-1, 1, -1, 1, 1, -1, -1, -1, -1, 1): 353,\n",
       " (-1, 1, -1, 1, 1, -1, -1, -1, 1, -1): 354,\n",
       " (-1, 1, -1, 1, 1, -1, -1, -1, 1, 1): 355,\n",
       " (-1, 1, -1, 1, 1, -1, -1, 1, -1, -1): 356,\n",
       " (-1, 1, -1, 1, 1, -1, -1, 1, -1, 1): 357,\n",
       " (-1, 1, -1, 1, 1, -1, -1, 1, 1, -1): 358,\n",
       " (-1, 1, -1, 1, 1, -1, -1, 1, 1, 1): 359,\n",
       " (-1, 1, -1, 1, 1, -1, 1, -1, -1, -1): 360,\n",
       " (-1, 1, -1, 1, 1, -1, 1, -1, -1, 1): 361,\n",
       " (-1, 1, -1, 1, 1, -1, 1, -1, 1, -1): 362,\n",
       " (-1, 1, -1, 1, 1, -1, 1, -1, 1, 1): 363,\n",
       " (-1, 1, -1, 1, 1, -1, 1, 1, -1, -1): 364,\n",
       " (-1, 1, -1, 1, 1, -1, 1, 1, -1, 1): 365,\n",
       " (-1, 1, -1, 1, 1, -1, 1, 1, 1, -1): 366,\n",
       " (-1, 1, -1, 1, 1, -1, 1, 1, 1, 1): 367,\n",
       " (-1, 1, -1, 1, 1, 1, -1, -1, -1, -1): 368,\n",
       " (-1, 1, -1, 1, 1, 1, -1, -1, -1, 1): 369,\n",
       " (-1, 1, -1, 1, 1, 1, -1, -1, 1, -1): 370,\n",
       " (-1, 1, -1, 1, 1, 1, -1, -1, 1, 1): 371,\n",
       " (-1, 1, -1, 1, 1, 1, -1, 1, -1, -1): 372,\n",
       " (-1, 1, -1, 1, 1, 1, -1, 1, -1, 1): 373,\n",
       " (-1, 1, -1, 1, 1, 1, -1, 1, 1, -1): 374,\n",
       " (-1, 1, -1, 1, 1, 1, -1, 1, 1, 1): 375,\n",
       " (-1, 1, -1, 1, 1, 1, 1, -1, -1, -1): 376,\n",
       " (-1, 1, -1, 1, 1, 1, 1, -1, -1, 1): 377,\n",
       " (-1, 1, -1, 1, 1, 1, 1, -1, 1, -1): 378,\n",
       " (-1, 1, -1, 1, 1, 1, 1, -1, 1, 1): 379,\n",
       " (-1, 1, -1, 1, 1, 1, 1, 1, -1, -1): 380,\n",
       " (-1, 1, -1, 1, 1, 1, 1, 1, -1, 1): 381,\n",
       " (-1, 1, -1, 1, 1, 1, 1, 1, 1, -1): 382,\n",
       " (-1, 1, -1, 1, 1, 1, 1, 1, 1, 1): 383,\n",
       " (-1, 1, 1, -1, -1, -1, -1, -1, -1, -1): 384,\n",
       " (-1, 1, 1, -1, -1, -1, -1, -1, -1, 1): 385,\n",
       " (-1, 1, 1, -1, -1, -1, -1, -1, 1, -1): 386,\n",
       " (-1, 1, 1, -1, -1, -1, -1, -1, 1, 1): 387,\n",
       " (-1, 1, 1, -1, -1, -1, -1, 1, -1, -1): 388,\n",
       " (-1, 1, 1, -1, -1, -1, -1, 1, -1, 1): 389,\n",
       " (-1, 1, 1, -1, -1, -1, -1, 1, 1, -1): 390,\n",
       " (-1, 1, 1, -1, -1, -1, -1, 1, 1, 1): 391,\n",
       " (-1, 1, 1, -1, -1, -1, 1, -1, -1, -1): 392,\n",
       " (-1, 1, 1, -1, -1, -1, 1, -1, -1, 1): 393,\n",
       " (-1, 1, 1, -1, -1, -1, 1, -1, 1, -1): 394,\n",
       " (-1, 1, 1, -1, -1, -1, 1, -1, 1, 1): 395,\n",
       " (-1, 1, 1, -1, -1, -1, 1, 1, -1, -1): 396,\n",
       " (-1, 1, 1, -1, -1, -1, 1, 1, -1, 1): 397,\n",
       " (-1, 1, 1, -1, -1, -1, 1, 1, 1, -1): 398,\n",
       " (-1, 1, 1, -1, -1, -1, 1, 1, 1, 1): 399,\n",
       " (-1, 1, 1, -1, -1, 1, -1, -1, -1, -1): 400,\n",
       " (-1, 1, 1, -1, -1, 1, -1, -1, -1, 1): 401,\n",
       " (-1, 1, 1, -1, -1, 1, -1, -1, 1, -1): 402,\n",
       " (-1, 1, 1, -1, -1, 1, -1, -1, 1, 1): 403,\n",
       " (-1, 1, 1, -1, -1, 1, -1, 1, -1, -1): 404,\n",
       " (-1, 1, 1, -1, -1, 1, -1, 1, -1, 1): 405,\n",
       " (-1, 1, 1, -1, -1, 1, -1, 1, 1, -1): 406,\n",
       " (-1, 1, 1, -1, -1, 1, -1, 1, 1, 1): 407,\n",
       " (-1, 1, 1, -1, -1, 1, 1, -1, -1, -1): 408,\n",
       " (-1, 1, 1, -1, -1, 1, 1, -1, -1, 1): 409,\n",
       " (-1, 1, 1, -1, -1, 1, 1, -1, 1, -1): 410,\n",
       " (-1, 1, 1, -1, -1, 1, 1, -1, 1, 1): 411,\n",
       " (-1, 1, 1, -1, -1, 1, 1, 1, -1, -1): 412,\n",
       " (-1, 1, 1, -1, -1, 1, 1, 1, -1, 1): 413,\n",
       " (-1, 1, 1, -1, -1, 1, 1, 1, 1, -1): 414,\n",
       " (-1, 1, 1, -1, -1, 1, 1, 1, 1, 1): 415,\n",
       " (-1, 1, 1, -1, 1, -1, -1, -1, -1, -1): 416,\n",
       " (-1, 1, 1, -1, 1, -1, -1, -1, -1, 1): 417,\n",
       " (-1, 1, 1, -1, 1, -1, -1, -1, 1, -1): 418,\n",
       " (-1, 1, 1, -1, 1, -1, -1, -1, 1, 1): 419,\n",
       " (-1, 1, 1, -1, 1, -1, -1, 1, -1, -1): 420,\n",
       " (-1, 1, 1, -1, 1, -1, -1, 1, -1, 1): 421,\n",
       " (-1, 1, 1, -1, 1, -1, -1, 1, 1, -1): 422,\n",
       " (-1, 1, 1, -1, 1, -1, -1, 1, 1, 1): 423,\n",
       " (-1, 1, 1, -1, 1, -1, 1, -1, -1, -1): 424,\n",
       " (-1, 1, 1, -1, 1, -1, 1, -1, -1, 1): 425,\n",
       " (-1, 1, 1, -1, 1, -1, 1, -1, 1, -1): 426,\n",
       " (-1, 1, 1, -1, 1, -1, 1, -1, 1, 1): 427,\n",
       " (-1, 1, 1, -1, 1, -1, 1, 1, -1, -1): 428,\n",
       " (-1, 1, 1, -1, 1, -1, 1, 1, -1, 1): 429,\n",
       " (-1, 1, 1, -1, 1, -1, 1, 1, 1, -1): 430,\n",
       " (-1, 1, 1, -1, 1, -1, 1, 1, 1, 1): 431,\n",
       " (-1, 1, 1, -1, 1, 1, -1, -1, -1, -1): 432,\n",
       " (-1, 1, 1, -1, 1, 1, -1, -1, -1, 1): 433,\n",
       " (-1, 1, 1, -1, 1, 1, -1, -1, 1, -1): 434,\n",
       " (-1, 1, 1, -1, 1, 1, -1, -1, 1, 1): 435,\n",
       " (-1, 1, 1, -1, 1, 1, -1, 1, -1, -1): 436,\n",
       " (-1, 1, 1, -1, 1, 1, -1, 1, -1, 1): 437,\n",
       " (-1, 1, 1, -1, 1, 1, -1, 1, 1, -1): 438,\n",
       " (-1, 1, 1, -1, 1, 1, -1, 1, 1, 1): 439,\n",
       " (-1, 1, 1, -1, 1, 1, 1, -1, -1, -1): 440,\n",
       " (-1, 1, 1, -1, 1, 1, 1, -1, -1, 1): 441,\n",
       " (-1, 1, 1, -1, 1, 1, 1, -1, 1, -1): 442,\n",
       " (-1, 1, 1, -1, 1, 1, 1, -1, 1, 1): 443,\n",
       " (-1, 1, 1, -1, 1, 1, 1, 1, -1, -1): 444,\n",
       " (-1, 1, 1, -1, 1, 1, 1, 1, -1, 1): 445,\n",
       " (-1, 1, 1, -1, 1, 1, 1, 1, 1, -1): 446,\n",
       " (-1, 1, 1, -1, 1, 1, 1, 1, 1, 1): 447,\n",
       " (-1, 1, 1, 1, -1, -1, -1, -1, -1, -1): 448,\n",
       " (-1, 1, 1, 1, -1, -1, -1, -1, -1, 1): 449,\n",
       " (-1, 1, 1, 1, -1, -1, -1, -1, 1, -1): 450,\n",
       " (-1, 1, 1, 1, -1, -1, -1, -1, 1, 1): 451,\n",
       " (-1, 1, 1, 1, -1, -1, -1, 1, -1, -1): 452,\n",
       " (-1, 1, 1, 1, -1, -1, -1, 1, -1, 1): 453,\n",
       " (-1, 1, 1, 1, -1, -1, -1, 1, 1, -1): 454,\n",
       " (-1, 1, 1, 1, -1, -1, -1, 1, 1, 1): 455,\n",
       " (-1, 1, 1, 1, -1, -1, 1, -1, -1, -1): 456,\n",
       " (-1, 1, 1, 1, -1, -1, 1, -1, -1, 1): 457,\n",
       " (-1, 1, 1, 1, -1, -1, 1, -1, 1, -1): 458,\n",
       " (-1, 1, 1, 1, -1, -1, 1, -1, 1, 1): 459,\n",
       " (-1, 1, 1, 1, -1, -1, 1, 1, -1, -1): 460,\n",
       " (-1, 1, 1, 1, -1, -1, 1, 1, -1, 1): 461,\n",
       " (-1, 1, 1, 1, -1, -1, 1, 1, 1, -1): 462,\n",
       " (-1, 1, 1, 1, -1, -1, 1, 1, 1, 1): 463,\n",
       " (-1, 1, 1, 1, -1, 1, -1, -1, -1, -1): 464,\n",
       " (-1, 1, 1, 1, -1, 1, -1, -1, -1, 1): 465,\n",
       " (-1, 1, 1, 1, -1, 1, -1, -1, 1, -1): 466,\n",
       " (-1, 1, 1, 1, -1, 1, -1, -1, 1, 1): 467,\n",
       " (-1, 1, 1, 1, -1, 1, -1, 1, -1, -1): 468,\n",
       " (-1, 1, 1, 1, -1, 1, -1, 1, -1, 1): 469,\n",
       " (-1, 1, 1, 1, -1, 1, -1, 1, 1, -1): 470,\n",
       " (-1, 1, 1, 1, -1, 1, -1, 1, 1, 1): 471,\n",
       " (-1, 1, 1, 1, -1, 1, 1, -1, -1, -1): 472,\n",
       " (-1, 1, 1, 1, -1, 1, 1, -1, -1, 1): 473,\n",
       " (-1, 1, 1, 1, -1, 1, 1, -1, 1, -1): 474,\n",
       " (-1, 1, 1, 1, -1, 1, 1, -1, 1, 1): 475,\n",
       " (-1, 1, 1, 1, -1, 1, 1, 1, -1, -1): 476,\n",
       " (-1, 1, 1, 1, -1, 1, 1, 1, -1, 1): 477,\n",
       " (-1, 1, 1, 1, -1, 1, 1, 1, 1, -1): 478,\n",
       " (-1, 1, 1, 1, -1, 1, 1, 1, 1, 1): 479,\n",
       " (-1, 1, 1, 1, 1, -1, -1, -1, -1, -1): 480,\n",
       " (-1, 1, 1, 1, 1, -1, -1, -1, -1, 1): 481,\n",
       " (-1, 1, 1, 1, 1, -1, -1, -1, 1, -1): 482,\n",
       " (-1, 1, 1, 1, 1, -1, -1, -1, 1, 1): 483,\n",
       " (-1, 1, 1, 1, 1, -1, -1, 1, -1, -1): 484,\n",
       " (-1, 1, 1, 1, 1, -1, -1, 1, -1, 1): 485,\n",
       " (-1, 1, 1, 1, 1, -1, -1, 1, 1, -1): 486,\n",
       " (-1, 1, 1, 1, 1, -1, -1, 1, 1, 1): 487,\n",
       " (-1, 1, 1, 1, 1, -1, 1, -1, -1, -1): 488,\n",
       " (-1, 1, 1, 1, 1, -1, 1, -1, -1, 1): 489,\n",
       " (-1, 1, 1, 1, 1, -1, 1, -1, 1, -1): 490,\n",
       " (-1, 1, 1, 1, 1, -1, 1, -1, 1, 1): 491,\n",
       " (-1, 1, 1, 1, 1, -1, 1, 1, -1, -1): 492,\n",
       " (-1, 1, 1, 1, 1, -1, 1, 1, -1, 1): 493,\n",
       " (-1, 1, 1, 1, 1, -1, 1, 1, 1, -1): 494,\n",
       " (-1, 1, 1, 1, 1, -1, 1, 1, 1, 1): 495,\n",
       " (-1, 1, 1, 1, 1, 1, -1, -1, -1, -1): 496,\n",
       " (-1, 1, 1, 1, 1, 1, -1, -1, -1, 1): 497,\n",
       " (-1, 1, 1, 1, 1, 1, -1, -1, 1, -1): 498,\n",
       " (-1, 1, 1, 1, 1, 1, -1, -1, 1, 1): 499,\n",
       " (-1, 1, 1, 1, 1, 1, -1, 1, -1, -1): 500,\n",
       " (-1, 1, 1, 1, 1, 1, -1, 1, -1, 1): 501,\n",
       " (-1, 1, 1, 1, 1, 1, -1, 1, 1, -1): 502,\n",
       " (-1, 1, 1, 1, 1, 1, -1, 1, 1, 1): 503,\n",
       " (-1, 1, 1, 1, 1, 1, 1, -1, -1, -1): 504,\n",
       " (-1, 1, 1, 1, 1, 1, 1, -1, -1, 1): 505,\n",
       " (-1, 1, 1, 1, 1, 1, 1, -1, 1, -1): 506,\n",
       " (-1, 1, 1, 1, 1, 1, 1, -1, 1, 1): 507,\n",
       " (-1, 1, 1, 1, 1, 1, 1, 1, -1, -1): 508,\n",
       " (-1, 1, 1, 1, 1, 1, 1, 1, -1, 1): 509,\n",
       " (-1, 1, 1, 1, 1, 1, 1, 1, 1, -1): 510,\n",
       " (-1, 1, 1, 1, 1, 1, 1, 1, 1, 1): 511,\n",
       " (1, -1, -1, -1, -1, -1, -1, -1, -1, -1): 512,\n",
       " (1, -1, -1, -1, -1, -1, -1, -1, -1, 1): 513,\n",
       " (1, -1, -1, -1, -1, -1, -1, -1, 1, -1): 514,\n",
       " (1, -1, -1, -1, -1, -1, -1, -1, 1, 1): 515,\n",
       " (1, -1, -1, -1, -1, -1, -1, 1, -1, -1): 516,\n",
       " (1, -1, -1, -1, -1, -1, -1, 1, -1, 1): 517,\n",
       " (1, -1, -1, -1, -1, -1, -1, 1, 1, -1): 518,\n",
       " (1, -1, -1, -1, -1, -1, -1, 1, 1, 1): 519,\n",
       " (1, -1, -1, -1, -1, -1, 1, -1, -1, -1): 520,\n",
       " (1, -1, -1, -1, -1, -1, 1, -1, -1, 1): 521,\n",
       " (1, -1, -1, -1, -1, -1, 1, -1, 1, -1): 522,\n",
       " (1, -1, -1, -1, -1, -1, 1, -1, 1, 1): 523,\n",
       " (1, -1, -1, -1, -1, -1, 1, 1, -1, -1): 524,\n",
       " (1, -1, -1, -1, -1, -1, 1, 1, -1, 1): 525,\n",
       " (1, -1, -1, -1, -1, -1, 1, 1, 1, -1): 526,\n",
       " (1, -1, -1, -1, -1, -1, 1, 1, 1, 1): 527,\n",
       " (1, -1, -1, -1, -1, 1, -1, -1, -1, -1): 528,\n",
       " (1, -1, -1, -1, -1, 1, -1, -1, -1, 1): 529,\n",
       " (1, -1, -1, -1, -1, 1, -1, -1, 1, -1): 530,\n",
       " (1, -1, -1, -1, -1, 1, -1, -1, 1, 1): 531,\n",
       " (1, -1, -1, -1, -1, 1, -1, 1, -1, -1): 532,\n",
       " (1, -1, -1, -1, -1, 1, -1, 1, -1, 1): 533,\n",
       " (1, -1, -1, -1, -1, 1, -1, 1, 1, -1): 534,\n",
       " (1, -1, -1, -1, -1, 1, -1, 1, 1, 1): 535,\n",
       " (1, -1, -1, -1, -1, 1, 1, -1, -1, -1): 536,\n",
       " (1, -1, -1, -1, -1, 1, 1, -1, -1, 1): 537,\n",
       " (1, -1, -1, -1, -1, 1, 1, -1, 1, -1): 538,\n",
       " (1, -1, -1, -1, -1, 1, 1, -1, 1, 1): 539,\n",
       " (1, -1, -1, -1, -1, 1, 1, 1, -1, -1): 540,\n",
       " (1, -1, -1, -1, -1, 1, 1, 1, -1, 1): 541,\n",
       " (1, -1, -1, -1, -1, 1, 1, 1, 1, -1): 542,\n",
       " (1, -1, -1, -1, -1, 1, 1, 1, 1, 1): 543,\n",
       " (1, -1, -1, -1, 1, -1, -1, -1, -1, -1): 544,\n",
       " (1, -1, -1, -1, 1, -1, -1, -1, -1, 1): 545,\n",
       " (1, -1, -1, -1, 1, -1, -1, -1, 1, -1): 546,\n",
       " (1, -1, -1, -1, 1, -1, -1, -1, 1, 1): 547,\n",
       " (1, -1, -1, -1, 1, -1, -1, 1, -1, -1): 548,\n",
       " (1, -1, -1, -1, 1, -1, -1, 1, -1, 1): 549,\n",
       " (1, -1, -1, -1, 1, -1, -1, 1, 1, -1): 550,\n",
       " (1, -1, -1, -1, 1, -1, -1, 1, 1, 1): 551,\n",
       " (1, -1, -1, -1, 1, -1, 1, -1, -1, -1): 552,\n",
       " (1, -1, -1, -1, 1, -1, 1, -1, -1, 1): 553,\n",
       " (1, -1, -1, -1, 1, -1, 1, -1, 1, -1): 554,\n",
       " (1, -1, -1, -1, 1, -1, 1, -1, 1, 1): 555,\n",
       " (1, -1, -1, -1, 1, -1, 1, 1, -1, -1): 556,\n",
       " (1, -1, -1, -1, 1, -1, 1, 1, -1, 1): 557,\n",
       " (1, -1, -1, -1, 1, -1, 1, 1, 1, -1): 558,\n",
       " (1, -1, -1, -1, 1, -1, 1, 1, 1, 1): 559,\n",
       " (1, -1, -1, -1, 1, 1, -1, -1, -1, -1): 560,\n",
       " (1, -1, -1, -1, 1, 1, -1, -1, -1, 1): 561,\n",
       " (1, -1, -1, -1, 1, 1, -1, -1, 1, -1): 562,\n",
       " (1, -1, -1, -1, 1, 1, -1, -1, 1, 1): 563,\n",
       " (1, -1, -1, -1, 1, 1, -1, 1, -1, -1): 564,\n",
       " (1, -1, -1, -1, 1, 1, -1, 1, -1, 1): 565,\n",
       " (1, -1, -1, -1, 1, 1, -1, 1, 1, -1): 566,\n",
       " (1, -1, -1, -1, 1, 1, -1, 1, 1, 1): 567,\n",
       " (1, -1, -1, -1, 1, 1, 1, -1, -1, -1): 568,\n",
       " (1, -1, -1, -1, 1, 1, 1, -1, -1, 1): 569,\n",
       " (1, -1, -1, -1, 1, 1, 1, -1, 1, -1): 570,\n",
       " (1, -1, -1, -1, 1, 1, 1, -1, 1, 1): 571,\n",
       " (1, -1, -1, -1, 1, 1, 1, 1, -1, -1): 572,\n",
       " (1, -1, -1, -1, 1, 1, 1, 1, -1, 1): 573,\n",
       " (1, -1, -1, -1, 1, 1, 1, 1, 1, -1): 574,\n",
       " (1, -1, -1, -1, 1, 1, 1, 1, 1, 1): 575,\n",
       " (1, -1, -1, 1, -1, -1, -1, -1, -1, -1): 576,\n",
       " (1, -1, -1, 1, -1, -1, -1, -1, -1, 1): 577,\n",
       " (1, -1, -1, 1, -1, -1, -1, -1, 1, -1): 578,\n",
       " (1, -1, -1, 1, -1, -1, -1, -1, 1, 1): 579,\n",
       " (1, -1, -1, 1, -1, -1, -1, 1, -1, -1): 580,\n",
       " (1, -1, -1, 1, -1, -1, -1, 1, -1, 1): 581,\n",
       " (1, -1, -1, 1, -1, -1, -1, 1, 1, -1): 582,\n",
       " (1, -1, -1, 1, -1, -1, -1, 1, 1, 1): 583,\n",
       " (1, -1, -1, 1, -1, -1, 1, -1, -1, -1): 584,\n",
       " (1, -1, -1, 1, -1, -1, 1, -1, -1, 1): 585,\n",
       " (1, -1, -1, 1, -1, -1, 1, -1, 1, -1): 586,\n",
       " (1, -1, -1, 1, -1, -1, 1, -1, 1, 1): 587,\n",
       " (1, -1, -1, 1, -1, -1, 1, 1, -1, -1): 588,\n",
       " (1, -1, -1, 1, -1, -1, 1, 1, -1, 1): 589,\n",
       " (1, -1, -1, 1, -1, -1, 1, 1, 1, -1): 590,\n",
       " (1, -1, -1, 1, -1, -1, 1, 1, 1, 1): 591,\n",
       " (1, -1, -1, 1, -1, 1, -1, -1, -1, -1): 592,\n",
       " (1, -1, -1, 1, -1, 1, -1, -1, -1, 1): 593,\n",
       " (1, -1, -1, 1, -1, 1, -1, -1, 1, -1): 594,\n",
       " (1, -1, -1, 1, -1, 1, -1, -1, 1, 1): 595,\n",
       " (1, -1, -1, 1, -1, 1, -1, 1, -1, -1): 596,\n",
       " (1, -1, -1, 1, -1, 1, -1, 1, -1, 1): 597,\n",
       " (1, -1, -1, 1, -1, 1, -1, 1, 1, -1): 598,\n",
       " (1, -1, -1, 1, -1, 1, -1, 1, 1, 1): 599,\n",
       " (1, -1, -1, 1, -1, 1, 1, -1, -1, -1): 600,\n",
       " (1, -1, -1, 1, -1, 1, 1, -1, -1, 1): 601,\n",
       " (1, -1, -1, 1, -1, 1, 1, -1, 1, -1): 602,\n",
       " (1, -1, -1, 1, -1, 1, 1, -1, 1, 1): 603,\n",
       " (1, -1, -1, 1, -1, 1, 1, 1, -1, -1): 604,\n",
       " (1, -1, -1, 1, -1, 1, 1, 1, -1, 1): 605,\n",
       " (1, -1, -1, 1, -1, 1, 1, 1, 1, -1): 606,\n",
       " (1, -1, -1, 1, -1, 1, 1, 1, 1, 1): 607,\n",
       " (1, -1, -1, 1, 1, -1, -1, -1, -1, -1): 608,\n",
       " (1, -1, -1, 1, 1, -1, -1, -1, -1, 1): 609,\n",
       " (1, -1, -1, 1, 1, -1, -1, -1, 1, -1): 610,\n",
       " (1, -1, -1, 1, 1, -1, -1, -1, 1, 1): 611,\n",
       " (1, -1, -1, 1, 1, -1, -1, 1, -1, -1): 612,\n",
       " (1, -1, -1, 1, 1, -1, -1, 1, -1, 1): 613,\n",
       " (1, -1, -1, 1, 1, -1, -1, 1, 1, -1): 614,\n",
       " (1, -1, -1, 1, 1, -1, -1, 1, 1, 1): 615,\n",
       " (1, -1, -1, 1, 1, -1, 1, -1, -1, -1): 616,\n",
       " (1, -1, -1, 1, 1, -1, 1, -1, -1, 1): 617,\n",
       " (1, -1, -1, 1, 1, -1, 1, -1, 1, -1): 618,\n",
       " (1, -1, -1, 1, 1, -1, 1, -1, 1, 1): 619,\n",
       " (1, -1, -1, 1, 1, -1, 1, 1, -1, -1): 620,\n",
       " (1, -1, -1, 1, 1, -1, 1, 1, -1, 1): 621,\n",
       " (1, -1, -1, 1, 1, -1, 1, 1, 1, -1): 622,\n",
       " (1, -1, -1, 1, 1, -1, 1, 1, 1, 1): 623,\n",
       " (1, -1, -1, 1, 1, 1, -1, -1, -1, -1): 624,\n",
       " (1, -1, -1, 1, 1, 1, -1, -1, -1, 1): 625,\n",
       " (1, -1, -1, 1, 1, 1, -1, -1, 1, -1): 626,\n",
       " (1, -1, -1, 1, 1, 1, -1, -1, 1, 1): 627,\n",
       " (1, -1, -1, 1, 1, 1, -1, 1, -1, -1): 628,\n",
       " (1, -1, -1, 1, 1, 1, -1, 1, -1, 1): 629,\n",
       " (1, -1, -1, 1, 1, 1, -1, 1, 1, -1): 630,\n",
       " (1, -1, -1, 1, 1, 1, -1, 1, 1, 1): 631,\n",
       " (1, -1, -1, 1, 1, 1, 1, -1, -1, -1): 632,\n",
       " (1, -1, -1, 1, 1, 1, 1, -1, -1, 1): 633,\n",
       " (1, -1, -1, 1, 1, 1, 1, -1, 1, -1): 634,\n",
       " (1, -1, -1, 1, 1, 1, 1, -1, 1, 1): 635,\n",
       " (1, -1, -1, 1, 1, 1, 1, 1, -1, -1): 636,\n",
       " (1, -1, -1, 1, 1, 1, 1, 1, -1, 1): 637,\n",
       " (1, -1, -1, 1, 1, 1, 1, 1, 1, -1): 638,\n",
       " (1, -1, -1, 1, 1, 1, 1, 1, 1, 1): 639,\n",
       " (1, -1, 1, -1, -1, -1, -1, -1, -1, -1): 640,\n",
       " (1, -1, 1, -1, -1, -1, -1, -1, -1, 1): 641,\n",
       " (1, -1, 1, -1, -1, -1, -1, -1, 1, -1): 642,\n",
       " (1, -1, 1, -1, -1, -1, -1, -1, 1, 1): 643,\n",
       " (1, -1, 1, -1, -1, -1, -1, 1, -1, -1): 644,\n",
       " (1, -1, 1, -1, -1, -1, -1, 1, -1, 1): 645,\n",
       " (1, -1, 1, -1, -1, -1, -1, 1, 1, -1): 646,\n",
       " (1, -1, 1, -1, -1, -1, -1, 1, 1, 1): 647,\n",
       " (1, -1, 1, -1, -1, -1, 1, -1, -1, -1): 648,\n",
       " (1, -1, 1, -1, -1, -1, 1, -1, -1, 1): 649,\n",
       " (1, -1, 1, -1, -1, -1, 1, -1, 1, -1): 650,\n",
       " (1, -1, 1, -1, -1, -1, 1, -1, 1, 1): 651,\n",
       " (1, -1, 1, -1, -1, -1, 1, 1, -1, -1): 652,\n",
       " (1, -1, 1, -1, -1, -1, 1, 1, -1, 1): 653,\n",
       " (1, -1, 1, -1, -1, -1, 1, 1, 1, -1): 654,\n",
       " (1, -1, 1, -1, -1, -1, 1, 1, 1, 1): 655,\n",
       " (1, -1, 1, -1, -1, 1, -1, -1, -1, -1): 656,\n",
       " (1, -1, 1, -1, -1, 1, -1, -1, -1, 1): 657,\n",
       " (1, -1, 1, -1, -1, 1, -1, -1, 1, -1): 658,\n",
       " (1, -1, 1, -1, -1, 1, -1, -1, 1, 1): 659,\n",
       " (1, -1, 1, -1, -1, 1, -1, 1, -1, -1): 660,\n",
       " (1, -1, 1, -1, -1, 1, -1, 1, -1, 1): 661,\n",
       " (1, -1, 1, -1, -1, 1, -1, 1, 1, -1): 662,\n",
       " (1, -1, 1, -1, -1, 1, -1, 1, 1, 1): 663,\n",
       " (1, -1, 1, -1, -1, 1, 1, -1, -1, -1): 664,\n",
       " (1, -1, 1, -1, -1, 1, 1, -1, -1, 1): 665,\n",
       " (1, -1, 1, -1, -1, 1, 1, -1, 1, -1): 666,\n",
       " (1, -1, 1, -1, -1, 1, 1, -1, 1, 1): 667,\n",
       " (1, -1, 1, -1, -1, 1, 1, 1, -1, -1): 668,\n",
       " (1, -1, 1, -1, -1, 1, 1, 1, -1, 1): 669,\n",
       " (1, -1, 1, -1, -1, 1, 1, 1, 1, -1): 670,\n",
       " (1, -1, 1, -1, -1, 1, 1, 1, 1, 1): 671,\n",
       " (1, -1, 1, -1, 1, -1, -1, -1, -1, -1): 672,\n",
       " (1, -1, 1, -1, 1, -1, -1, -1, -1, 1): 673,\n",
       " (1, -1, 1, -1, 1, -1, -1, -1, 1, -1): 674,\n",
       " (1, -1, 1, -1, 1, -1, -1, -1, 1, 1): 675,\n",
       " (1, -1, 1, -1, 1, -1, -1, 1, -1, -1): 676,\n",
       " (1, -1, 1, -1, 1, -1, -1, 1, -1, 1): 677,\n",
       " (1, -1, 1, -1, 1, -1, -1, 1, 1, -1): 678,\n",
       " (1, -1, 1, -1, 1, -1, -1, 1, 1, 1): 679,\n",
       " (1, -1, 1, -1, 1, -1, 1, -1, -1, -1): 680,\n",
       " (1, -1, 1, -1, 1, -1, 1, -1, -1, 1): 681,\n",
       " (1, -1, 1, -1, 1, -1, 1, -1, 1, -1): 682,\n",
       " (1, -1, 1, -1, 1, -1, 1, -1, 1, 1): 683,\n",
       " (1, -1, 1, -1, 1, -1, 1, 1, -1, -1): 684,\n",
       " (1, -1, 1, -1, 1, -1, 1, 1, -1, 1): 685,\n",
       " (1, -1, 1, -1, 1, -1, 1, 1, 1, -1): 686,\n",
       " (1, -1, 1, -1, 1, -1, 1, 1, 1, 1): 687,\n",
       " (1, -1, 1, -1, 1, 1, -1, -1, -1, -1): 688,\n",
       " (1, -1, 1, -1, 1, 1, -1, -1, -1, 1): 689,\n",
       " (1, -1, 1, -1, 1, 1, -1, -1, 1, -1): 690,\n",
       " (1, -1, 1, -1, 1, 1, -1, -1, 1, 1): 691,\n",
       " (1, -1, 1, -1, 1, 1, -1, 1, -1, -1): 692,\n",
       " (1, -1, 1, -1, 1, 1, -1, 1, -1, 1): 693,\n",
       " (1, -1, 1, -1, 1, 1, -1, 1, 1, -1): 694,\n",
       " (1, -1, 1, -1, 1, 1, -1, 1, 1, 1): 695,\n",
       " (1, -1, 1, -1, 1, 1, 1, -1, -1, -1): 696,\n",
       " (1, -1, 1, -1, 1, 1, 1, -1, -1, 1): 697,\n",
       " (1, -1, 1, -1, 1, 1, 1, -1, 1, -1): 698,\n",
       " (1, -1, 1, -1, 1, 1, 1, -1, 1, 1): 699,\n",
       " (1, -1, 1, -1, 1, 1, 1, 1, -1, -1): 700,\n",
       " (1, -1, 1, -1, 1, 1, 1, 1, -1, 1): 701,\n",
       " (1, -1, 1, -1, 1, 1, 1, 1, 1, -1): 702,\n",
       " (1, -1, 1, -1, 1, 1, 1, 1, 1, 1): 703,\n",
       " (1, -1, 1, 1, -1, -1, -1, -1, -1, -1): 704,\n",
       " (1, -1, 1, 1, -1, -1, -1, -1, -1, 1): 705,\n",
       " (1, -1, 1, 1, -1, -1, -1, -1, 1, -1): 706,\n",
       " (1, -1, 1, 1, -1, -1, -1, -1, 1, 1): 707,\n",
       " (1, -1, 1, 1, -1, -1, -1, 1, -1, -1): 708,\n",
       " (1, -1, 1, 1, -1, -1, -1, 1, -1, 1): 709,\n",
       " (1, -1, 1, 1, -1, -1, -1, 1, 1, -1): 710,\n",
       " (1, -1, 1, 1, -1, -1, -1, 1, 1, 1): 711,\n",
       " (1, -1, 1, 1, -1, -1, 1, -1, -1, -1): 712,\n",
       " (1, -1, 1, 1, -1, -1, 1, -1, -1, 1): 713,\n",
       " (1, -1, 1, 1, -1, -1, 1, -1, 1, -1): 714,\n",
       " (1, -1, 1, 1, -1, -1, 1, -1, 1, 1): 715,\n",
       " (1, -1, 1, 1, -1, -1, 1, 1, -1, -1): 716,\n",
       " (1, -1, 1, 1, -1, -1, 1, 1, -1, 1): 717,\n",
       " (1, -1, 1, 1, -1, -1, 1, 1, 1, -1): 718,\n",
       " (1, -1, 1, 1, -1, -1, 1, 1, 1, 1): 719,\n",
       " (1, -1, 1, 1, -1, 1, -1, -1, -1, -1): 720,\n",
       " (1, -1, 1, 1, -1, 1, -1, -1, -1, 1): 721,\n",
       " (1, -1, 1, 1, -1, 1, -1, -1, 1, -1): 722,\n",
       " (1, -1, 1, 1, -1, 1, -1, -1, 1, 1): 723,\n",
       " (1, -1, 1, 1, -1, 1, -1, 1, -1, -1): 724,\n",
       " (1, -1, 1, 1, -1, 1, -1, 1, -1, 1): 725,\n",
       " (1, -1, 1, 1, -1, 1, -1, 1, 1, -1): 726,\n",
       " (1, -1, 1, 1, -1, 1, -1, 1, 1, 1): 727,\n",
       " (1, -1, 1, 1, -1, 1, 1, -1, -1, -1): 728,\n",
       " (1, -1, 1, 1, -1, 1, 1, -1, -1, 1): 729,\n",
       " (1, -1, 1, 1, -1, 1, 1, -1, 1, -1): 730,\n",
       " (1, -1, 1, 1, -1, 1, 1, -1, 1, 1): 731,\n",
       " (1, -1, 1, 1, -1, 1, 1, 1, -1, -1): 732,\n",
       " (1, -1, 1, 1, -1, 1, 1, 1, -1, 1): 733,\n",
       " (1, -1, 1, 1, -1, 1, 1, 1, 1, -1): 734,\n",
       " (1, -1, 1, 1, -1, 1, 1, 1, 1, 1): 735,\n",
       " (1, -1, 1, 1, 1, -1, -1, -1, -1, -1): 736,\n",
       " (1, -1, 1, 1, 1, -1, -1, -1, -1, 1): 737,\n",
       " (1, -1, 1, 1, 1, -1, -1, -1, 1, -1): 738,\n",
       " (1, -1, 1, 1, 1, -1, -1, -1, 1, 1): 739,\n",
       " (1, -1, 1, 1, 1, -1, -1, 1, -1, -1): 740,\n",
       " (1, -1, 1, 1, 1, -1, -1, 1, -1, 1): 741,\n",
       " (1, -1, 1, 1, 1, -1, -1, 1, 1, -1): 742,\n",
       " (1, -1, 1, 1, 1, -1, -1, 1, 1, 1): 743,\n",
       " (1, -1, 1, 1, 1, -1, 1, -1, -1, -1): 744,\n",
       " (1, -1, 1, 1, 1, -1, 1, -1, -1, 1): 745,\n",
       " (1, -1, 1, 1, 1, -1, 1, -1, 1, -1): 746,\n",
       " (1, -1, 1, 1, 1, -1, 1, -1, 1, 1): 747,\n",
       " (1, -1, 1, 1, 1, -1, 1, 1, -1, -1): 748,\n",
       " (1, -1, 1, 1, 1, -1, 1, 1, -1, 1): 749,\n",
       " (1, -1, 1, 1, 1, -1, 1, 1, 1, -1): 750,\n",
       " (1, -1, 1, 1, 1, -1, 1, 1, 1, 1): 751,\n",
       " (1, -1, 1, 1, 1, 1, -1, -1, -1, -1): 752,\n",
       " (1, -1, 1, 1, 1, 1, -1, -1, -1, 1): 753,\n",
       " (1, -1, 1, 1, 1, 1, -1, -1, 1, -1): 754,\n",
       " (1, -1, 1, 1, 1, 1, -1, -1, 1, 1): 755,\n",
       " (1, -1, 1, 1, 1, 1, -1, 1, -1, -1): 756,\n",
       " (1, -1, 1, 1, 1, 1, -1, 1, -1, 1): 757,\n",
       " (1, -1, 1, 1, 1, 1, -1, 1, 1, -1): 758,\n",
       " (1, -1, 1, 1, 1, 1, -1, 1, 1, 1): 759,\n",
       " (1, -1, 1, 1, 1, 1, 1, -1, -1, -1): 760,\n",
       " (1, -1, 1, 1, 1, 1, 1, -1, -1, 1): 761,\n",
       " (1, -1, 1, 1, 1, 1, 1, -1, 1, -1): 762,\n",
       " (1, -1, 1, 1, 1, 1, 1, -1, 1, 1): 763,\n",
       " (1, -1, 1, 1, 1, 1, 1, 1, -1, -1): 764,\n",
       " (1, -1, 1, 1, 1, 1, 1, 1, -1, 1): 765,\n",
       " (1, -1, 1, 1, 1, 1, 1, 1, 1, -1): 766,\n",
       " (1, -1, 1, 1, 1, 1, 1, 1, 1, 1): 767,\n",
       " (1, 1, -1, -1, -1, -1, -1, -1, -1, -1): 768,\n",
       " (1, 1, -1, -1, -1, -1, -1, -1, -1, 1): 769,\n",
       " (1, 1, -1, -1, -1, -1, -1, -1, 1, -1): 770,\n",
       " (1, 1, -1, -1, -1, -1, -1, -1, 1, 1): 771,\n",
       " (1, 1, -1, -1, -1, -1, -1, 1, -1, -1): 772,\n",
       " (1, 1, -1, -1, -1, -1, -1, 1, -1, 1): 773,\n",
       " (1, 1, -1, -1, -1, -1, -1, 1, 1, -1): 774,\n",
       " (1, 1, -1, -1, -1, -1, -1, 1, 1, 1): 775,\n",
       " (1, 1, -1, -1, -1, -1, 1, -1, -1, -1): 776,\n",
       " (1, 1, -1, -1, -1, -1, 1, -1, -1, 1): 777,\n",
       " (1, 1, -1, -1, -1, -1, 1, -1, 1, -1): 778,\n",
       " (1, 1, -1, -1, -1, -1, 1, -1, 1, 1): 779,\n",
       " (1, 1, -1, -1, -1, -1, 1, 1, -1, -1): 780,\n",
       " (1, 1, -1, -1, -1, -1, 1, 1, -1, 1): 781,\n",
       " (1, 1, -1, -1, -1, -1, 1, 1, 1, -1): 782,\n",
       " (1, 1, -1, -1, -1, -1, 1, 1, 1, 1): 783,\n",
       " (1, 1, -1, -1, -1, 1, -1, -1, -1, -1): 784,\n",
       " (1, 1, -1, -1, -1, 1, -1, -1, -1, 1): 785,\n",
       " (1, 1, -1, -1, -1, 1, -1, -1, 1, -1): 786,\n",
       " (1, 1, -1, -1, -1, 1, -1, -1, 1, 1): 787,\n",
       " (1, 1, -1, -1, -1, 1, -1, 1, -1, -1): 788,\n",
       " (1, 1, -1, -1, -1, 1, -1, 1, -1, 1): 789,\n",
       " (1, 1, -1, -1, -1, 1, -1, 1, 1, -1): 790,\n",
       " (1, 1, -1, -1, -1, 1, -1, 1, 1, 1): 791,\n",
       " (1, 1, -1, -1, -1, 1, 1, -1, -1, -1): 792,\n",
       " (1, 1, -1, -1, -1, 1, 1, -1, -1, 1): 793,\n",
       " (1, 1, -1, -1, -1, 1, 1, -1, 1, -1): 794,\n",
       " (1, 1, -1, -1, -1, 1, 1, -1, 1, 1): 795,\n",
       " (1, 1, -1, -1, -1, 1, 1, 1, -1, -1): 796,\n",
       " (1, 1, -1, -1, -1, 1, 1, 1, -1, 1): 797,\n",
       " (1, 1, -1, -1, -1, 1, 1, 1, 1, -1): 798,\n",
       " (1, 1, -1, -1, -1, 1, 1, 1, 1, 1): 799,\n",
       " (1, 1, -1, -1, 1, -1, -1, -1, -1, -1): 800,\n",
       " (1, 1, -1, -1, 1, -1, -1, -1, -1, 1): 801,\n",
       " (1, 1, -1, -1, 1, -1, -1, -1, 1, -1): 802,\n",
       " (1, 1, -1, -1, 1, -1, -1, -1, 1, 1): 803,\n",
       " (1, 1, -1, -1, 1, -1, -1, 1, -1, -1): 804,\n",
       " (1, 1, -1, -1, 1, -1, -1, 1, -1, 1): 805,\n",
       " (1, 1, -1, -1, 1, -1, -1, 1, 1, -1): 806,\n",
       " (1, 1, -1, -1, 1, -1, -1, 1, 1, 1): 807,\n",
       " (1, 1, -1, -1, 1, -1, 1, -1, -1, -1): 808,\n",
       " (1, 1, -1, -1, 1, -1, 1, -1, -1, 1): 809,\n",
       " (1, 1, -1, -1, 1, -1, 1, -1, 1, -1): 810,\n",
       " (1, 1, -1, -1, 1, -1, 1, -1, 1, 1): 811,\n",
       " (1, 1, -1, -1, 1, -1, 1, 1, -1, -1): 812,\n",
       " (1, 1, -1, -1, 1, -1, 1, 1, -1, 1): 813,\n",
       " (1, 1, -1, -1, 1, -1, 1, 1, 1, -1): 814,\n",
       " (1, 1, -1, -1, 1, -1, 1, 1, 1, 1): 815,\n",
       " (1, 1, -1, -1, 1, 1, -1, -1, -1, -1): 816,\n",
       " (1, 1, -1, -1, 1, 1, -1, -1, -1, 1): 817,\n",
       " (1, 1, -1, -1, 1, 1, -1, -1, 1, -1): 818,\n",
       " (1, 1, -1, -1, 1, 1, -1, -1, 1, 1): 819,\n",
       " (1, 1, -1, -1, 1, 1, -1, 1, -1, -1): 820,\n",
       " (1, 1, -1, -1, 1, 1, -1, 1, -1, 1): 821,\n",
       " (1, 1, -1, -1, 1, 1, -1, 1, 1, -1): 822,\n",
       " (1, 1, -1, -1, 1, 1, -1, 1, 1, 1): 823,\n",
       " (1, 1, -1, -1, 1, 1, 1, -1, -1, -1): 824,\n",
       " (1, 1, -1, -1, 1, 1, 1, -1, -1, 1): 825,\n",
       " (1, 1, -1, -1, 1, 1, 1, -1, 1, -1): 826,\n",
       " (1, 1, -1, -1, 1, 1, 1, -1, 1, 1): 827,\n",
       " (1, 1, -1, -1, 1, 1, 1, 1, -1, -1): 828,\n",
       " (1, 1, -1, -1, 1, 1, 1, 1, -1, 1): 829,\n",
       " (1, 1, -1, -1, 1, 1, 1, 1, 1, -1): 830,\n",
       " (1, 1, -1, -1, 1, 1, 1, 1, 1, 1): 831,\n",
       " (1, 1, -1, 1, -1, -1, -1, -1, -1, -1): 832,\n",
       " (1, 1, -1, 1, -1, -1, -1, -1, -1, 1): 833,\n",
       " (1, 1, -1, 1, -1, -1, -1, -1, 1, -1): 834,\n",
       " (1, 1, -1, 1, -1, -1, -1, -1, 1, 1): 835,\n",
       " (1, 1, -1, 1, -1, -1, -1, 1, -1, -1): 836,\n",
       " (1, 1, -1, 1, -1, -1, -1, 1, -1, 1): 837,\n",
       " (1, 1, -1, 1, -1, -1, -1, 1, 1, -1): 838,\n",
       " (1, 1, -1, 1, -1, -1, -1, 1, 1, 1): 839,\n",
       " (1, 1, -1, 1, -1, -1, 1, -1, -1, -1): 840,\n",
       " (1, 1, -1, 1, -1, -1, 1, -1, -1, 1): 841,\n",
       " (1, 1, -1, 1, -1, -1, 1, -1, 1, -1): 842,\n",
       " (1, 1, -1, 1, -1, -1, 1, -1, 1, 1): 843,\n",
       " (1, 1, -1, 1, -1, -1, 1, 1, -1, -1): 844,\n",
       " (1, 1, -1, 1, -1, -1, 1, 1, -1, 1): 845,\n",
       " (1, 1, -1, 1, -1, -1, 1, 1, 1, -1): 846,\n",
       " (1, 1, -1, 1, -1, -1, 1, 1, 1, 1): 847,\n",
       " (1, 1, -1, 1, -1, 1, -1, -1, -1, -1): 848,\n",
       " (1, 1, -1, 1, -1, 1, -1, -1, -1, 1): 849,\n",
       " (1, 1, -1, 1, -1, 1, -1, -1, 1, -1): 850,\n",
       " (1, 1, -1, 1, -1, 1, -1, -1, 1, 1): 851,\n",
       " (1, 1, -1, 1, -1, 1, -1, 1, -1, -1): 852,\n",
       " (1, 1, -1, 1, -1, 1, -1, 1, -1, 1): 853,\n",
       " (1, 1, -1, 1, -1, 1, -1, 1, 1, -1): 854,\n",
       " (1, 1, -1, 1, -1, 1, -1, 1, 1, 1): 855,\n",
       " (1, 1, -1, 1, -1, 1, 1, -1, -1, -1): 856,\n",
       " (1, 1, -1, 1, -1, 1, 1, -1, -1, 1): 857,\n",
       " (1, 1, -1, 1, -1, 1, 1, -1, 1, -1): 858,\n",
       " (1, 1, -1, 1, -1, 1, 1, -1, 1, 1): 859,\n",
       " (1, 1, -1, 1, -1, 1, 1, 1, -1, -1): 860,\n",
       " (1, 1, -1, 1, -1, 1, 1, 1, -1, 1): 861,\n",
       " (1, 1, -1, 1, -1, 1, 1, 1, 1, -1): 862,\n",
       " (1, 1, -1, 1, -1, 1, 1, 1, 1, 1): 863,\n",
       " (1, 1, -1, 1, 1, -1, -1, -1, -1, -1): 864,\n",
       " (1, 1, -1, 1, 1, -1, -1, -1, -1, 1): 865,\n",
       " (1, 1, -1, 1, 1, -1, -1, -1, 1, -1): 866,\n",
       " (1, 1, -1, 1, 1, -1, -1, -1, 1, 1): 867,\n",
       " (1, 1, -1, 1, 1, -1, -1, 1, -1, -1): 868,\n",
       " (1, 1, -1, 1, 1, -1, -1, 1, -1, 1): 869,\n",
       " (1, 1, -1, 1, 1, -1, -1, 1, 1, -1): 870,\n",
       " (1, 1, -1, 1, 1, -1, -1, 1, 1, 1): 871,\n",
       " (1, 1, -1, 1, 1, -1, 1, -1, -1, -1): 872,\n",
       " (1, 1, -1, 1, 1, -1, 1, -1, -1, 1): 873,\n",
       " (1, 1, -1, 1, 1, -1, 1, -1, 1, -1): 874,\n",
       " (1, 1, -1, 1, 1, -1, 1, -1, 1, 1): 875,\n",
       " (1, 1, -1, 1, 1, -1, 1, 1, -1, -1): 876,\n",
       " (1, 1, -1, 1, 1, -1, 1, 1, -1, 1): 877,\n",
       " (1, 1, -1, 1, 1, -1, 1, 1, 1, -1): 878,\n",
       " (1, 1, -1, 1, 1, -1, 1, 1, 1, 1): 879,\n",
       " (1, 1, -1, 1, 1, 1, -1, -1, -1, -1): 880,\n",
       " (1, 1, -1, 1, 1, 1, -1, -1, -1, 1): 881,\n",
       " (1, 1, -1, 1, 1, 1, -1, -1, 1, -1): 882,\n",
       " (1, 1, -1, 1, 1, 1, -1, -1, 1, 1): 883,\n",
       " (1, 1, -1, 1, 1, 1, -1, 1, -1, -1): 884,\n",
       " (1, 1, -1, 1, 1, 1, -1, 1, -1, 1): 885,\n",
       " (1, 1, -1, 1, 1, 1, -1, 1, 1, -1): 886,\n",
       " (1, 1, -1, 1, 1, 1, -1, 1, 1, 1): 887,\n",
       " (1, 1, -1, 1, 1, 1, 1, -1, -1, -1): 888,\n",
       " (1, 1, -1, 1, 1, 1, 1, -1, -1, 1): 889,\n",
       " (1, 1, -1, 1, 1, 1, 1, -1, 1, -1): 890,\n",
       " (1, 1, -1, 1, 1, 1, 1, -1, 1, 1): 891,\n",
       " (1, 1, -1, 1, 1, 1, 1, 1, -1, -1): 892,\n",
       " (1, 1, -1, 1, 1, 1, 1, 1, -1, 1): 893,\n",
       " (1, 1, -1, 1, 1, 1, 1, 1, 1, -1): 894,\n",
       " (1, 1, -1, 1, 1, 1, 1, 1, 1, 1): 895,\n",
       " (1, 1, 1, -1, -1, -1, -1, -1, -1, -1): 896,\n",
       " (1, 1, 1, -1, -1, -1, -1, -1, -1, 1): 897,\n",
       " (1, 1, 1, -1, -1, -1, -1, -1, 1, -1): 898,\n",
       " (1, 1, 1, -1, -1, -1, -1, -1, 1, 1): 899,\n",
       " (1, 1, 1, -1, -1, -1, -1, 1, -1, -1): 900,\n",
       " (1, 1, 1, -1, -1, -1, -1, 1, -1, 1): 901,\n",
       " (1, 1, 1, -1, -1, -1, -1, 1, 1, -1): 902,\n",
       " (1, 1, 1, -1, -1, -1, -1, 1, 1, 1): 903,\n",
       " (1, 1, 1, -1, -1, -1, 1, -1, -1, -1): 904,\n",
       " (1, 1, 1, -1, -1, -1, 1, -1, -1, 1): 905,\n",
       " (1, 1, 1, -1, -1, -1, 1, -1, 1, -1): 906,\n",
       " (1, 1, 1, -1, -1, -1, 1, -1, 1, 1): 907,\n",
       " (1, 1, 1, -1, -1, -1, 1, 1, -1, -1): 908,\n",
       " (1, 1, 1, -1, -1, -1, 1, 1, -1, 1): 909,\n",
       " (1, 1, 1, -1, -1, -1, 1, 1, 1, -1): 910,\n",
       " (1, 1, 1, -1, -1, -1, 1, 1, 1, 1): 911,\n",
       " (1, 1, 1, -1, -1, 1, -1, -1, -1, -1): 912,\n",
       " (1, 1, 1, -1, -1, 1, -1, -1, -1, 1): 913,\n",
       " (1, 1, 1, -1, -1, 1, -1, -1, 1, -1): 914,\n",
       " (1, 1, 1, -1, -1, 1, -1, -1, 1, 1): 915,\n",
       " (1, 1, 1, -1, -1, 1, -1, 1, -1, -1): 916,\n",
       " (1, 1, 1, -1, -1, 1, -1, 1, -1, 1): 917,\n",
       " (1, 1, 1, -1, -1, 1, -1, 1, 1, -1): 918,\n",
       " (1, 1, 1, -1, -1, 1, -1, 1, 1, 1): 919,\n",
       " (1, 1, 1, -1, -1, 1, 1, -1, -1, -1): 920,\n",
       " (1, 1, 1, -1, -1, 1, 1, -1, -1, 1): 921,\n",
       " (1, 1, 1, -1, -1, 1, 1, -1, 1, -1): 922,\n",
       " (1, 1, 1, -1, -1, 1, 1, -1, 1, 1): 923,\n",
       " (1, 1, 1, -1, -1, 1, 1, 1, -1, -1): 924,\n",
       " (1, 1, 1, -1, -1, 1, 1, 1, -1, 1): 925,\n",
       " (1, 1, 1, -1, -1, 1, 1, 1, 1, -1): 926,\n",
       " (1, 1, 1, -1, -1, 1, 1, 1, 1, 1): 927,\n",
       " (1, 1, 1, -1, 1, -1, -1, -1, -1, -1): 928,\n",
       " (1, 1, 1, -1, 1, -1, -1, -1, -1, 1): 929,\n",
       " (1, 1, 1, -1, 1, -1, -1, -1, 1, -1): 930,\n",
       " (1, 1, 1, -1, 1, -1, -1, -1, 1, 1): 931,\n",
       " (1, 1, 1, -1, 1, -1, -1, 1, -1, -1): 932,\n",
       " (1, 1, 1, -1, 1, -1, -1, 1, -1, 1): 933,\n",
       " (1, 1, 1, -1, 1, -1, -1, 1, 1, -1): 934,\n",
       " (1, 1, 1, -1, 1, -1, -1, 1, 1, 1): 935,\n",
       " (1, 1, 1, -1, 1, -1, 1, -1, -1, -1): 936,\n",
       " (1, 1, 1, -1, 1, -1, 1, -1, -1, 1): 937,\n",
       " (1, 1, 1, -1, 1, -1, 1, -1, 1, -1): 938,\n",
       " (1, 1, 1, -1, 1, -1, 1, -1, 1, 1): 939,\n",
       " (1, 1, 1, -1, 1, -1, 1, 1, -1, -1): 940,\n",
       " (1, 1, 1, -1, 1, -1, 1, 1, -1, 1): 941,\n",
       " (1, 1, 1, -1, 1, -1, 1, 1, 1, -1): 942,\n",
       " (1, 1, 1, -1, 1, -1, 1, 1, 1, 1): 943,\n",
       " (1, 1, 1, -1, 1, 1, -1, -1, -1, -1): 944,\n",
       " (1, 1, 1, -1, 1, 1, -1, -1, -1, 1): 945,\n",
       " (1, 1, 1, -1, 1, 1, -1, -1, 1, -1): 946,\n",
       " (1, 1, 1, -1, 1, 1, -1, -1, 1, 1): 947,\n",
       " (1, 1, 1, -1, 1, 1, -1, 1, -1, -1): 948,\n",
       " (1, 1, 1, -1, 1, 1, -1, 1, -1, 1): 949,\n",
       " (1, 1, 1, -1, 1, 1, -1, 1, 1, -1): 950,\n",
       " (1, 1, 1, -1, 1, 1, -1, 1, 1, 1): 951,\n",
       " (1, 1, 1, -1, 1, 1, 1, -1, -1, -1): 952,\n",
       " (1, 1, 1, -1, 1, 1, 1, -1, -1, 1): 953,\n",
       " (1, 1, 1, -1, 1, 1, 1, -1, 1, -1): 954,\n",
       " (1, 1, 1, -1, 1, 1, 1, -1, 1, 1): 955,\n",
       " (1, 1, 1, -1, 1, 1, 1, 1, -1, -1): 956,\n",
       " (1, 1, 1, -1, 1, 1, 1, 1, -1, 1): 957,\n",
       " (1, 1, 1, -1, 1, 1, 1, 1, 1, -1): 958,\n",
       " (1, 1, 1, -1, 1, 1, 1, 1, 1, 1): 959,\n",
       " (1, 1, 1, 1, -1, -1, -1, -1, -1, -1): 960,\n",
       " (1, 1, 1, 1, -1, -1, -1, -1, -1, 1): 961,\n",
       " (1, 1, 1, 1, -1, -1, -1, -1, 1, -1): 962,\n",
       " (1, 1, 1, 1, -1, -1, -1, -1, 1, 1): 963,\n",
       " (1, 1, 1, 1, -1, -1, -1, 1, -1, -1): 964,\n",
       " (1, 1, 1, 1, -1, -1, -1, 1, -1, 1): 965,\n",
       " (1, 1, 1, 1, -1, -1, -1, 1, 1, -1): 966,\n",
       " (1, 1, 1, 1, -1, -1, -1, 1, 1, 1): 967,\n",
       " (1, 1, 1, 1, -1, -1, 1, -1, -1, -1): 968,\n",
       " (1, 1, 1, 1, -1, -1, 1, -1, -1, 1): 969,\n",
       " (1, 1, 1, 1, -1, -1, 1, -1, 1, -1): 970,\n",
       " (1, 1, 1, 1, -1, -1, 1, -1, 1, 1): 971,\n",
       " (1, 1, 1, 1, -1, -1, 1, 1, -1, -1): 972,\n",
       " (1, 1, 1, 1, -1, -1, 1, 1, -1, 1): 973,\n",
       " (1, 1, 1, 1, -1, -1, 1, 1, 1, -1): 974,\n",
       " (1, 1, 1, 1, -1, -1, 1, 1, 1, 1): 975,\n",
       " (1, 1, 1, 1, -1, 1, -1, -1, -1, -1): 976,\n",
       " (1, 1, 1, 1, -1, 1, -1, -1, -1, 1): 977,\n",
       " (1, 1, 1, 1, -1, 1, -1, -1, 1, -1): 978,\n",
       " (1, 1, 1, 1, -1, 1, -1, -1, 1, 1): 979,\n",
       " (1, 1, 1, 1, -1, 1, -1, 1, -1, -1): 980,\n",
       " (1, 1, 1, 1, -1, 1, -1, 1, -1, 1): 981,\n",
       " (1, 1, 1, 1, -1, 1, -1, 1, 1, -1): 982,\n",
       " (1, 1, 1, 1, -1, 1, -1, 1, 1, 1): 983,\n",
       " (1, 1, 1, 1, -1, 1, 1, -1, -1, -1): 984,\n",
       " (1, 1, 1, 1, -1, 1, 1, -1, -1, 1): 985,\n",
       " (1, 1, 1, 1, -1, 1, 1, -1, 1, -1): 986,\n",
       " (1, 1, 1, 1, -1, 1, 1, -1, 1, 1): 987,\n",
       " (1, 1, 1, 1, -1, 1, 1, 1, -1, -1): 988,\n",
       " (1, 1, 1, 1, -1, 1, 1, 1, -1, 1): 989,\n",
       " (1, 1, 1, 1, -1, 1, 1, 1, 1, -1): 990,\n",
       " (1, 1, 1, 1, -1, 1, 1, 1, 1, 1): 991,\n",
       " (1, 1, 1, 1, 1, -1, -1, -1, -1, -1): 992,\n",
       " (1, 1, 1, 1, 1, -1, -1, -1, -1, 1): 993,\n",
       " (1, 1, 1, 1, 1, -1, -1, -1, 1, -1): 994,\n",
       " (1, 1, 1, 1, 1, -1, -1, -1, 1, 1): 995,\n",
       " (1, 1, 1, 1, 1, -1, -1, 1, -1, -1): 996,\n",
       " (1, 1, 1, 1, 1, -1, -1, 1, -1, 1): 997,\n",
       " (1, 1, 1, 1, 1, -1, -1, 1, 1, -1): 998,\n",
       " (1, 1, 1, 1, 1, -1, -1, 1, 1, 1): 999,\n",
       " ...}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = all_configs(n)\n",
    "idx_map = {tuple(c): i for i, c in enumerate(configs)}\n",
    "idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f9a1a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, array([1023, 1022, 1021, 1020, 1019], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spinconf2int(configs[0]), spins_to_index(configs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c74bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d2d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e8cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch gradient test passed.\n",
      "Batch logpdf test passed.\n",
      "Spin to index mapping test passed.\n",
      "Batched MALA step matches single-step for B=1.\n",
      "✅ All tests passed!\n"
     ]
    }
   ],
   "source": [
    "class ProblemInst:\n",
    "    n: int\n",
    "    T: float                     # inverse temperature (as used in your code)\n",
    "    J_quantum: np.ndarray        # shape (n, n), symmetric\n",
    "    h_quantum: np.ndarray        # shape (n,)\n",
    "    E_arr: np.ndarray            # length 2^n\n",
    "\n",
    "# def build_problem(n: int, seed: int = 0) -> ProblemInst:\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     # Symmetric J with small entries:\n",
    "#     A = rng.normal(0, 0.2, size=(n, n))\n",
    "#     J = 0.5 * (A + A.T)\n",
    "#     h = rng.normal(0, 0.2, size=n)\n",
    "\n",
    "#     V = all_configs(n)  # (2^n, n) in {-1,+1}\n",
    "#     # Classical Ising energy (sign convention chosen to be consistent)\n",
    "#     # E(v) = - v^T J v - h^T v\n",
    "#     E = np.einsum('bi,ij,bj->b', V, -J, V) - V @ h\n",
    "\n",
    "#     return ProblemInst(n=n, T=1.0, J_quantum=J, h_quantum=h, E_arr=E.astype(float))\n",
    "\n",
    "\n",
    "def assert_allclose(a, b, tol=1e-10, msg=\"\"):\n",
    "    if not np.allclose(a, b, atol=tol, rtol=0):\n",
    "        raise AssertionError(msg or f\"Arrays differ. Max abs diff: {np.max(np.abs(a-b))}\")\n",
    "\n",
    "def test_grad_agrees():\n",
    "    prob = problem_inst #build_problem(n, seed=1)\n",
    "    n = prob.n\n",
    "    x = np.linspace(-1.0, 1.0, n)\n",
    "    \n",
    "    alpha = 3.0\n",
    "    g1 = grad_U_mala(x, prob.J_quantum, prob.h_quantum, alpha)\n",
    "    g2 = grad_U_mala_batch(x[None, :], prob.J_quantum, prob.h_quantum, alpha)[0]\n",
    "    assert_allclose(g1, g2, 1e-12, \"grad_U_mala vs grad_U_mala_batch disagree (B=1)\")\n",
    "\n",
    "    # Also check a real batch\n",
    "    X = np.vstack([x, -x, 0.3 * x])\n",
    "    G = grad_U_mala_batch(X, prob.J_quantum, prob.h_quantum, alpha)\n",
    "    # spot check row 0 equals g1\n",
    "    assert_allclose(G[0], g1, 1e-12, \"Batch gradient first row mismatch\")\n",
    "    print(\"Batch gradient test passed.\")\n",
    "\n",
    "def test_logpdf_agrees():\n",
    "    n = 4\n",
    "    rng = np.random.default_rng(2)\n",
    "    y = rng.normal(size=n)\n",
    "    mean = rng.normal(size=n)\n",
    "    # SPD cov and its cholesky P\n",
    "    A = rng.normal(size=(n, n))\n",
    "    cov = A @ A.T + 0.1 * np.eye(n)\n",
    "    P = np.linalg.cholesky(cov)\n",
    "    eps = 0.7\n",
    "\n",
    "    lp1 = normal_dist_logpdf(y, mean, P, eps)\n",
    "    lp2 = normal_dist_logpdf_batch(y[None, :], mean[None, :], P, eps)[0]\n",
    "    assert_allclose(lp1, lp2, 1e-12, \"normal_dist_logpdf vs batch disagree (B=1)\")\n",
    "\n",
    "    # multi-B should equal element-wise\n",
    "    Y = np.vstack([y, y + 0.2, y - 0.1])\n",
    "    M = np.vstack([mean, mean + 0.1, mean - 0.2])\n",
    "    lpB = normal_dist_logpdf_batch(Y, M, P, eps)\n",
    "    for i in range(3):\n",
    "        lpi = normal_dist_logpdf(Y[i], M[i], P, eps)\n",
    "        assert_allclose(lpB[i], lpi, 1e-12, f\"logpdf row {i} mismatch\")\n",
    "    print(\"Batch logpdf test passed.\")\n",
    "\n",
    "def test_spin_index_mapping():\n",
    "    for n in range(1, 6):\n",
    "        V = all_configs(n)\n",
    "        idx_batch = spins_to_index(V)\n",
    "        idx_scalar = np.array([spinconf2int(v) for v in V])\n",
    "        if not np.array_equal(idx_batch, idx_scalar):\n",
    "            raise AssertionError(f\"spins_to_index disagrees with spinconf2int for n={n}\")\n",
    "    print(\"Spin to index mapping test passed.\") \n",
    "\n",
    "class RNGPatch:\n",
    "    \"\"\"Context manager to patch np.random.multivariate_normal to use randn, so\n",
    "    both single-step and batched-step draw from the SAME primitive RNG calls.\n",
    "    This allows exact equality tests for B=1 when seeding identically.\n",
    "    \"\"\"\n",
    "    def __enter__(self):\n",
    "        self._orig_mvn = np.random.multivariate_normal\n",
    "        def mvn(mean=None, cov=None, size=None, check_valid=None, tol=None):\n",
    "            mean = np.asarray(mean)\n",
    "            n = mean.size\n",
    "            if size is None:\n",
    "                z = np.random.randn(n)\n",
    "                P = np.linalg.cholesky(cov)  # cov is eps^2 P P^T in the call sites\n",
    "                return mean + z @ P.T\n",
    "            else:\n",
    "                if size != 1:\n",
    "                    raise NotImplementedError(\"This test patch only supports size=1 for the single-step function.\")\n",
    "                z = np.random.randn(n)\n",
    "                P = np.linalg.cholesky(cov)\n",
    "                return np.array([mean + z @ P.T])\n",
    "        np.random.multivariate_normal = mvn\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        np.random.multivariate_normal = self._orig_mvn\n",
    "\n",
    "def test_mala_step_equivalence_B1():\n",
    "    prob = problem_inst #build_problem(n, seed=3)\n",
    "    n = prob.n\n",
    "    alpha = 3.0\n",
    "    eps = 0.3\n",
    "\n",
    "    rng = np.random.default_rng(123)\n",
    "    x0 = rng.normal(size=n)\n",
    "    cov = np.eye(n)\n",
    "    cov_jit = cov + 1e-5 * np.eye(n)  # to mirror single-step jitter inside adaptive_MALA_step_new\n",
    "    P = np.linalg.cholesky(cov)\n",
    "\n",
    "    seeds = [7, 11, 19, 23, 29]\n",
    "    with RNGPatch():\n",
    "        for s in seeds:\n",
    "            np.random.seed(s)\n",
    "            x1, v1 = adaptive_MALA_step_new(x0.copy(), P, cov.copy(), eps, prob, alpha=alpha)\n",
    "\n",
    "            np.random.seed(s)\n",
    "            X2, V2 = adaptive_MALA_step_new_batch(x0[None, :].copy(), P, cov_jit.copy(), eps, prob, alpha=alpha)\n",
    "            x2, v2 = X2[0], V2[0]\n",
    "\n",
    "            if not np.allclose(x1, x2, atol=1e-12, rtol=0):\n",
    "                raise AssertionError(f\"MALA step x mismatch for seed {s} (max diff {np.max(np.abs(x1-x2))})\")\n",
    "            if not np.array_equal(v1, v2):\n",
    "                raise AssertionError(f\"MALA step v mismatch for seed {s}\")\n",
    "    print(\"Batched MALA step matches single-step for B=1.\")\n",
    "\n",
    "def run_all():\n",
    "    test_grad_agrees()\n",
    "    test_logpdf_agrees()\n",
    "    test_spin_index_mapping()\n",
    "    test_mala_step_equivalence_B1()\n",
    "    print(\"✅ All tests passed!\")\n",
    "\n",
    "run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb751c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
