{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff29ae-43cb-4557-8c72-f92582169082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyscf import gto, scf, fci, lo\n",
    "import netket as nk; import netket.experimental as nkx\n",
    "import numpy as np\n",
    "import itertools\n",
    "import qiskit\n",
    "from qiskit.quantum_info import Pauli, SparsePauliOp\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "#sys.path.append(os.path.dirname(os.getcwd()) + \"/SAMPLER_LOCAL_IMPORT\")\n",
    "#from Sampling_Quantum import *\n",
    "#from New_MCMC_Proposal import *\n",
    "sys.path.append(os.getcwd() + \"/Code_download_Bell_2\")\n",
    "from MCMC_funs_Leyden import *\n",
    "\n",
    "print(qiskit.version.get_version_info())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c6d12-f2be-40af-92a7-ef64965dabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_configs(n):\n",
    "    return [np.array(v) for v in product([-1, 1], repeat=n)]\n",
    "\n",
    "\n",
    "\n",
    "def Sampling_MCMC_trajectories(problem_inst, Transition_matrix, sample_size=10000, \n",
    "                               burn=1000, method='Quantum', init_config=None):\n",
    "\n",
    "    n = problem_inst.n\n",
    "    beta = problem_inst.T\n",
    "    prob_dist = np.zeros(2**n)\n",
    "\n",
    "    #exact_dist = np.exp(-beta * Proposal_object.Energy_array)\n",
    "    #exact_dist = exact_dist / np.sum(exact_dist)\n",
    "\n",
    "    #err_hist = []\n",
    "    key_list = []\n",
    "\n",
    "    if init_config==None:\n",
    "        s = np.random.choice([1,-1],size=n)\n",
    "    else: s = init_config\n",
    "\n",
    "    int_key = spinconf2int(s)\n",
    "    #print(int_key)\n",
    "    \n",
    "    for k in range(burn):\n",
    "        #s = Proposal_object.generate_MCMC_trajectories(Transition_matrix, s)\n",
    "         int_key = generate_move(transition_mat=Transition_matrix, state=int_key)\n",
    "\n",
    "    for k in range(sample_size):\n",
    "        #s = Proposal_object.generate_MCMC_trajectories(Transition_matrix, s)\n",
    "        int_key = generate_move(transition_mat=Transition_matrix, state=int_key)\n",
    "        #key = spinconf2int(s)\n",
    "        prob_dist[int_key] +=1\n",
    "        key_list.append(int_key)\n",
    "\n",
    "    \n",
    "    return np.flip(prob_dist/np.sum(prob_dist)), key_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grad_U(x, J, h, alpha):\n",
    "    v = np.tanh(alpha * x)\n",
    "    sech_sq = 1.0 * (1 - v ** 2)\n",
    "    return alpha * sech_sq * (h + 2 * J @ v)\n",
    "\n",
    "\n",
    "def adaptive_MALA_step_new(x, cov, epsilon, problem_inst, alpha=3.0):\n",
    "    J_Q = problem_inst.J_quantum\n",
    "    h_Q = problem_inst.h_quantum\n",
    "    cov = cov + 1e-6 * np.eye(len(x))\n",
    "\n",
    "    mean_shift = x + epsilon * problem_inst.T * cov @ grad_U(x, J_Q, h_Q, alpha)\n",
    "    noise = np.random.multivariate_normal(np.zeros(len(x)), epsilon**2 * cov)\n",
    "    x_new = mean_shift + noise\n",
    "\n",
    "    v_old = np.sign(np.tanh(alpha * x))\n",
    "    v_new = np.sign(np.tanh(alpha * x_new))\n",
    "    E_old = problem_inst.E_arr[::-1][spinconf2int(v_old)]\n",
    "    E_new = problem_inst.E_arr[::-1][spinconf2int(v_new)]\n",
    "\n",
    "    log_q_forward = -0.5 * noise.T @ np.linalg.inv(epsilon**2 * cov) @ noise\n",
    "    noise_rev = x - x_new + epsilon * cov @ grad_U(x_new, J_Q, h_Q, alpha)\n",
    "    log_q_reverse = -0.5 * noise_rev.T @ np.linalg.inv(epsilon**2 * cov) @ noise_rev\n",
    "\n",
    "    log_accept_ratio = -problem_inst.T * (E_new - E_old) + (log_q_reverse - log_q_forward)\n",
    "    accept_prob = min(1.0, np.exp(log_accept_ratio))\n",
    "\n",
    "    if np.random.rand() < accept_prob:\n",
    "        return x_new, v_new\n",
    "    else:\n",
    "        return x, v_old\n",
    "\n",
    "\n",
    "def adaptive_MALA_T_matrix(problem_inst, alpha=3.0, epsilon=0.3, num_samples=500):\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    n = problem_inst.n\n",
    "    #beta = problem_inst.T\n",
    "\n",
    "    configs = all_configs(n)\n",
    "    idx_map = {tuple(c): i for i, c in enumerate(configs)}\n",
    "    T = np.zeros((2**n, 2**n))\n",
    "\n",
    "    for v in tqdm(configs, desc=\"Building T matrix\"):\n",
    "        x = np.arctanh(np.clip(v, -0.999, 0.999)) / alpha\n",
    "        cov = np.eye(n)\n",
    "\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        v_samples = []\n",
    "        adapt_window = 20\n",
    "\n",
    "        for step in range(num_samples):\n",
    "            #x, v_new = adaptive_MALA_step(x, cov, epsilon, problem_inst, alpha=3.0)\n",
    "            x, v_new = adaptive_MALA_step_new(x, cov, epsilon, problem_inst, alpha=3.0)\n",
    "            v_samples.append(v_new)\n",
    "\n",
    "            key = tuple(v_new.astype(int))\n",
    "            counts[key] = counts.get(key, 0) + 1\n",
    "\n",
    "            if (step + 1) % adapt_window == 0 and step > 0:\n",
    "                if len(v_samples) >= 50:\n",
    "                    x_hist = np.array([np.arctanh(np.clip(np.tanh(alpha * x0), -0.999, 0.999)) / alpha for x0 in v_samples[-50:]])\n",
    "\n",
    "                else:\n",
    "                    x_hist = np.array([np.arctanh(np.clip(np.tanh(alpha * x0), -0.999, 0.999)) / alpha for x0 in v_samples])\n",
    "\n",
    "                cov = np.cov(x_hist.T)\n",
    "\n",
    "        i = idx_map[tuple(v)]\n",
    "        total = sum(counts.values())\n",
    "\n",
    "        for v_prime, c in counts.items():\n",
    "            j = idx_map[v_prime]\n",
    "\n",
    "            if j != i :\n",
    "                T[j, i] = c / total\n",
    "\n",
    "        T[i,i] = 1-sum(T[:,i])\n",
    "\n",
    "    T = normalize_transition_matrix(T, eps=1e-12, verbose=True)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc36a91-7a55-49db-9870-dd9c8f9e7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_result_reader_writer(filepath, filename_instances):\n",
    "    from tqdm import tqdm\n",
    "    instances = pd.read_pickle(filepath + filename_instances)\n",
    "    tot_instances = np.max(instances['Instance Number'].values)\n",
    "    print(tot_instances)\n",
    "    tot_instances = 10\n",
    "    results = pd.DataFrame(columns = [\n",
    "        'Instance Number',\n",
    "        'Spins', \n",
    "        'Temperature', \n",
    "        'Connectivity',\n",
    "        'Proposal',\n",
    "        'Acceptance',\n",
    "#    'Mismatched',\n",
    "        'Gap',\n",
    "        'Gap Lazy'\n",
    "           ])\n",
    "    T_logmesh = np.logspace(-3, 3, 50)\n",
    "    T_round = np.sort( np.kron(np.array([1,5]), 10.**np.arange(-3,4)))\n",
    "    T_lim = np.array([0, np.inf]) \n",
    "    T_arr = np.unique( np.concatenate((T_logmesh, T_round, T_lim))) \n",
    "    #T_arr = np.delete(T_arr, -2) \n",
    "    T_arr = [1]\n",
    "    delta_step = 0.2\n",
    "\n",
    "    for instance_num in range(1, tot_instances+1):\n",
    "    \n",
    "        cond  = (instances['Instance Number']==instance_num)\n",
    "        n            = instances[cond]['Spins'].values[0]\n",
    "        connectivity = instances[cond]['Connectivity'].values[0]\n",
    "        J            = instances[cond]['J'].values[0]\n",
    "        h            = instances[cond]['h'].values[0]\n",
    "        #J_mismatch   = instances[cond]['J Mismatch'].values[0]\n",
    "        #h_mismatch   = instances[cond]['h Mismatch'].values[0]\n",
    "\n",
    "        print('Starting problem instance', instance_num, 'of', tot_instances, 'with n =', n)\n",
    "\n",
    "        problem_inst = ProblemInstance(J, h)\n",
    "        #problem_inst_mismatch = ProblemInstance(J_mismatch, h_mismatch)\n",
    "\n",
    "        proposal_mats = {}\n",
    "        proposal_mats['local'] = local_proposal_mat(n)\n",
    "        proposal_mats['uniform']= uniform_proposal_mat(n)\n",
    "        proposal_mats['Haar']= Haar_random_proposal_mat(n)\n",
    "        proposal_mats['quantum_avg'] = quantum_proposal_mat_avg(problem_inst)\n",
    "        #proposal_mats['quantum_time_mid_gamma_mid'] = quantum_proposal_time_homogeneous(problem_inst, t_val=\"t_mid\")\n",
    "        proposal_mats['quantum_time_mid_gamma_mid_Trotter'] = quantum_proposal_time_homogeneous_Trotter_circuit(problem_inst, delta_step, t_val=\"t_mid\")\n",
    "        \n",
    "        #proposal_mats['quantum_time_uplim_gamma_mid'] = quantum_proposal_time_homogeneous(problem_inst, t_val=\"t-uplim\")\n",
    "        #proposal_mats['quantum_time_lowlim_gamma_mid'] = quantum_proposal_time_homogeneous(problem_inst, t_val=\"t-llim\")\n",
    "    \n",
    "        #norm_diff_trotter_exact_proposal = np.linalg.norm(proposal_mats['quantum_time_mid_gamma_mid_Trotter']-proposal_mats['quantum_time_mid_gamma_mid'])\n",
    "        #norm_exact_proposal = np.linalg.norm(proposal_mats['quantum_time_mid_gamma_mid'])\n",
    "\n",
    "        for T in T_arr:\n",
    "            problem_inst.T = T\n",
    "            #problem_inst_mismatch.T = T \n",
    "            #proposal_mats['Wolff_cluster_update'] = Wolff_cluster_Proposal_matrix(problem_inst)\n",
    "\n",
    "            #for prop_type, accept_type in product(['local', 'uniform', 'quantum'], ['metropolis', 'glauber']):\n",
    "            #for prop_type, accept_type in product(['local', 'uniform', 'quantum_avg', 'Haar', \n",
    "            #                                   'quantum_time_mid_gamma_mid_Trotter', 'Wolff_cluster_update', 'Exchange_cluster',\n",
    "            #                                    \"Continuous-HMC\", \"Random_walk_MC\", \"MALA_MC\"], ['metropolis']):    #\n",
    "\n",
    "            #for prop_type, accept_type in product([\"Random_walk_MC\"], ['metropolis']):    # \n",
    "            for prop_type, accept_type in product([\"MALA_MC\"], ['metropolis']):     \n",
    "\n",
    "\n",
    "                if prop_type == \"Continuous-HMC\":\n",
    "                    #transition_mat = HMC_T_matrix(problem_inst, epsilon=0.2, L=10, alpha=3.0, num_samples=500, num_p_samples=30)\n",
    "                    transition_mat = HMC_T_matrix_vectorized(problem_inst, epsilon=0.2, L=10, alpha=3.0,\n",
    "                            num_samples=800, num_p_samples=40)\n",
    "\n",
    "                elif prop_type == \"Random_walk_MC\":\n",
    "                    transition_mat = RWM_T_matrix(problem_inst, alpha=3.0, epsilon=0.2, num_samples=1000)\n",
    "                    print(transition_mat, np.linalg.eigvals(transition_mat))\n",
    "                #elif prop_type == \"MALA_MC\":\n",
    "                #    transition_mat = adaptive_MALA_T_matrix(problem_inst, alpha=3.0, epsilon=0.2, num_samples=500)\n",
    "\n",
    "                elif prop_type == \"MALA_MC\":\n",
    "                    #pass\n",
    "                    #transition_mat = build_transition_matrix_mala(problem_inst, \n",
    "                    #                                              epsilon=0.2, alpha=3.0, num_samples=500, adapt_every=10)\n",
    "                    transition_mat = adaptive_MALA_T_matrix(problem_inst, alpha=3.0, epsilon=0.2, num_samples=1000)\n",
    "                    #print(transition_mat, np.linalg.eigvals(transition_mat))\n",
    "\n",
    "                elif prop_type == 'Exchange_cluster':\n",
    "                    transition_mat = Exchange_cluster_transition_matrix(problem_inst, num_samples=2000)\n",
    "\n",
    "                else:\n",
    "                    transition_mat = make_transition_mat(problem_inst, proposal_mats[prop_type], acceptance=accept_type)\n",
    "                    \n",
    "                \n",
    "                gap, gap_lazy = abs_spectral_gap(transition_mat)\n",
    "                print(gap)\n",
    "\n",
    "                results_datum = {\n",
    "                    'Instance Number': instance_num,\n",
    "                    'Spins': n, \n",
    "                    'Temperature': T, \n",
    "                    'Connectivity': connectivity,\n",
    "                    'Proposal': prop_type,\n",
    "                    'Acceptance': accept_type,\n",
    "                    'Mismatched': False,\n",
    "                    'Gap': gap,\n",
    "                    'Gap Lazy': gap_lazy,\n",
    "                    \"delta_time_step_Trotter\": delta_step\n",
    "                }\n",
    "\n",
    "\n",
    "               results = pd.concat([results,pd.DataFrame([results_datum])], ignore_index=True)\n",
    "\n",
    "\n",
    "filepath = '/Users/msajjan/Desktop/PROJECTS/RBM_phase_project/PLOTS/CONVERGENCE_COMPARISON_DATA/250_instances_run_Jul_1st/LOCAL_MACHINE_IMPORT'\n",
    "filename_instances =  '/instances_new.pkl'\n",
    "\n",
    "instance_result_reader_writer(filepath=filepath, filename_instances=filename_instances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
