{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e04fa5-fa5d-42a8-af44-646c508cfc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\vinit\\\\Downloads\\\\Research\\\\Quantum-Sampling\\\\Manas' Proposals\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pyscf import gto, scf, fci, lo\n",
    "#import netket as nk; import netket.experimental as nkx\n",
    "import numpy as np\n",
    "import time\n",
    "#import itertools\n",
    "import qiskit\n",
    "#from qiskit.quantum_info import Pauli, SparsePauliOp\n",
    "from collections import defaultdict\n",
    "#import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "#import itertools\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "#sys.path.append(os.path.dirname(os.getcwd()) + \"/SAMPLER_LOCAL_IMPORT\")\n",
    "#from Sampling_Quantum import *\n",
    "#from New_MCMC_Proposal import *\n",
    "#sys.path.append(os.getcwd() + \"/Code_download_Bell_2\")\n",
    "from MCMC_funs_Leyden import *\n",
    "\n",
    "print(qiskit.version.get_version_info())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50fce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 1000 * 100 * 8\n",
    "n = 3\n",
    "P_flat = np.random.normal(size=(Q, n))                  # (Q, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f103f",
   "metadata": {},
   "source": [
    "## Non-vectorized HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1251853c-1ceb-47bf-8051-064855a4df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_configs(n):\n",
    "    return [np.array(v) for v in product([-1, 1], repeat=n)]\n",
    "\n",
    "\n",
    "\n",
    "def Sampling_MCMC_trajectories(problem_inst, Transition_matrix, sample_size=10000, \n",
    "                               burn=1000, method='Quantum', init_config=None):\n",
    "\n",
    "    n = problem_inst.n\n",
    "    beta = problem_inst.T\n",
    "    prob_dist = np.zeros(2**n)\n",
    "\n",
    "    #exact_dist = np.exp(-beta * Proposal_object.Energy_array)\n",
    "    #exact_dist = exact_dist / np.sum(exact_dist)\n",
    "\n",
    "    #err_hist = []\n",
    "    key_list = []\n",
    "\n",
    "    if init_config==None:\n",
    "        s = np.random.choice([1,-1],size=n)\n",
    "    else: s = init_config\n",
    "\n",
    "    int_key = spinconf2int(s)\n",
    "    #print(int_key)\n",
    "    \n",
    "    for k in range(burn):\n",
    "        #s = Proposal_object.generate_MCMC_trajectories(Transition_matrix, s)\n",
    "         int_key = generate_move(transition_mat=Transition_matrix, state=int_key)\n",
    "\n",
    "    for k in range(sample_size):\n",
    "        #s = Proposal_object.generate_MCMC_trajectories(Transition_matrix, s)\n",
    "        int_key = generate_move(transition_mat=Transition_matrix, state=int_key)\n",
    "        #key = spinconf2int(s)\n",
    "        prob_dist[int_key] +=1\n",
    "        key_list.append(int_key)\n",
    "\n",
    "    \n",
    "    return np.flip(prob_dist/np.sum(prob_dist)), key_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Continuous variable encoding (Hamiltonian Monte Carlo, Adaptive MCMC)\n",
    "#*********************************************************************\n",
    "\n",
    "\n",
    "def normalize_transition_matrix(T, eps=1e-12, verbose=False):\n",
    "   \n",
    "    T = np.copy(T)  \n",
    "    T[T < 0] = 0.0  \n",
    "\n",
    "    for j in range(T.shape[1]):\n",
    "        col_sum = T[:, j].sum()\n",
    "        if abs(col_sum) > eps:\n",
    "            T[:, j] /= abs(col_sum)\n",
    "        else:\n",
    "            # Uniform fallback for ill-defined columns\n",
    "            T[:, j] = 1.0 / T.shape[0]\n",
    "            if verbose:\n",
    "                print(f\"Warning: column {j} had zero or near-zero sum. Reset to uniform.\")\n",
    "\n",
    "    # Validate after normalization\n",
    "    if verbose:\n",
    "        for j in range(T.shape[1]):\n",
    "            if not np.isclose(T[:, j].sum(), 1.0, atol=1e-6):\n",
    "                print(f\"Column {j} sum = {T[:, j].sum()} (should be 1.0)\")\n",
    "            if np.any(T[:, j] < 0):\n",
    "                print(f\"Negative entries found in column {j}: {T[:, j][T[:, j] < 0]}\")\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "\n",
    "def grad_U(x, J, h, alpha):\n",
    "    #v = np.sign(np.tanh(alpha * x))\n",
    "    t = np.tanh(alpha * x)\n",
    "    sech_sq = 1.0 * (1 - t ** 2)\n",
    "    return alpha * sech_sq * (h + 2 * J @ t)\n",
    "\n",
    "\n",
    "\n",
    "def leapfrog_integrator(x, p, grad_U, epsilon, L, J, h, alpha):\n",
    "    # Integrates hamilton's eqn of motion\n",
    "    x_new = np.copy(x)\n",
    "    p_new = np.copy(p) - 0.5 * epsilon * grad_U(x_new, J, h, alpha)\n",
    "    for _ in range(L):\n",
    "        x_new += epsilon * p_new\n",
    "        if _ != L - 1:\n",
    "            p_new -= epsilon * grad_U(x_new, J, h, alpha)\n",
    "    p_new -= 0.5 * epsilon * grad_U(x_new, J, h, alpha)\n",
    "    return x_new, p_new\n",
    "\n",
    "\n",
    "def HMC_step(v, problem_inst, epsilon, L, alpha=2.0, num_p_samples=10):\n",
    "    \"\"\"HMC update for binary v using multiple momentum samples\"\"\"\n",
    "    J_Q = problem_inst.J_quantum\n",
    "    h_Q = problem_inst.h_quantum\n",
    "    n = problem_inst.n\n",
    "    beta = problem_inst.T\n",
    "    \n",
    "    x = np.arctanh(np.clip(v, -0.999, 0.999)) / alpha\n",
    "    counts = {}\n",
    "\n",
    "    for _ in range(num_p_samples):\n",
    "        p = np.random.normal(size=n)\n",
    "\n",
    "        v_old = np.sign(np.tanh(alpha * x))\n",
    "        \n",
    "        #U_x_init = config_energies[2**n - Proposal_object.get_spinconfig_to_int(v_old)-1]\n",
    "        U_x_init = problem_inst.E_arr[::-1][spinconf2int(v_old)]\n",
    "        H_init = 0.5 * np.sum(p**2) + U_x_init\n",
    "\n",
    "        \n",
    "        x_new, p_new = leapfrog_integrator(x, p, grad_U, epsilon, L, J_Q, h_Q, alpha)\n",
    "        v_new = np.sign(np.tanh(alpha * x_new))\n",
    "\n",
    "        U_x_final = problem_inst.E_arr[::-1][spinconf2int(v_new)]\n",
    "        H_final = 0.5 * np.sum(p_new**2) + U_x_final\n",
    "\n",
    "        accept_prob = min(1.0, np.exp(-(beta*H_final - beta*H_init)))\n",
    "\n",
    "  \n",
    "        if np.random.rand() < accept_prob:\n",
    "            v_tuple = tuple(v_new.astype(int))\n",
    "        else:\n",
    "            v_tuple = tuple(v.astype(int))\n",
    "\n",
    "        counts[v_tuple] = counts.get(v_tuple, 0) + 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "def HMC_T_matrix(problem_inst, epsilon=0.1, L=10, alpha=3.0, num_samples=100, num_p_samples=10):\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    n = problem_inst.n\n",
    "    \n",
    "    configs = all_configs(n)\n",
    "    idx_map = {tuple(c): i for i, c in enumerate(configs)}\n",
    "    T = np.zeros((2**n, 2**n))\n",
    "\n",
    "    for v in tqdm(configs, desc=\"Building T matrix\"):\n",
    "        aggregate_counts = {}\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            counts = HMC_step(np.array(v),problem_inst, epsilon, L, alpha, num_p_samples)\n",
    "\n",
    "            for k, val in counts.items():\n",
    "                aggregate_counts[k] = aggregate_counts.get(k, 0) + val\n",
    "    \n",
    "        i = idx_map[tuple(v)]\n",
    "        total = sum(aggregate_counts.values())\n",
    "        for v_prime, c in aggregate_counts.items():\n",
    "            \n",
    "            j = idx_map[v_prime]\n",
    "            if j != i :\n",
    "                T[j, i] = c / total\n",
    "            #if j != i:\n",
    "            #    T[i, j] = c / total\n",
    "\n",
    "            #else:\n",
    "        T[i,i] = 1-sum(T[:,i])    \n",
    "\n",
    "    T = normalize_transition_matrix(T, eps=1e-12, verbose=True)\n",
    "\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea102a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_configs(n):\n",
    "    return [np.array(v) for v in product([-1, 1], repeat=n)]\n",
    "\n",
    "\n",
    "def spins_to_int(V):\n",
    "    \"\"\"\n",
    "    V: (..., n) in {-1,+1}. Enumerated via all_configs(n).\n",
    "    Maps (-1->0, +1->1) with weights 2^(n-1-k) so that\n",
    "    \"\"\"\n",
    "    V = np.asarray(V)\n",
    "    n = V.shape[-1]\n",
    "    bits = (V > 0).astype(np.uint64)                      # (..., n)\n",
    "    weights = (1 << np.arange(n-1, -1, -1, dtype=np.uint64))  # (n,) MSB-first\n",
    "    return (bits * weights).sum(axis=-1).astype(np.int64)\n",
    "\n",
    "V = all_configs(3)\n",
    "spins_to_int(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877188e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d1e0cb",
   "metadata": {},
   "source": [
    "## Vectorized HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd018a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4194304"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 << 22 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f47879b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_transition_matrix(T, eps=1e-12, verbose=False):\n",
    "    T = T.copy()\n",
    "    T[T < 0] = 0.0\n",
    "    col_sums = T.sum(axis=0)\n",
    "    bad = np.abs(col_sums) <= eps\n",
    "    good = ~bad\n",
    "    if np.any(good):\n",
    "        T[:, good] /= col_sums[None, good]\n",
    "    if np.any(bad):\n",
    "        T[:, bad] = 1.0 / T.shape[0]\n",
    "        if verbose:\n",
    "            print(f\"{bad.sum()} columns had near-zero sum. Reset to uniform.\")\n",
    "    return T\n",
    "\n",
    "\n",
    "def grad_U(X, J, H, alpha):\n",
    "    \"\"\"\n",
    "    X: (Q, n) or (n,) \n",
    "    J: (n, n), H: (n,)\n",
    "    Returns grad shape like X.\n",
    "    \"\"\"\n",
    "    T = np.tanh(alpha * X)                # continuous spins\n",
    "    sech2 = 1.0 - T*T\n",
    "    G = T @ J.T                           # vectorized J@T (row-wise)\n",
    "    return alpha * sech2 * (H + 2.0 * G)\n",
    "\n",
    "\n",
    "# --- Vectorized leapfrog ---\n",
    "def leapfrog_integrator_batch(X, P, grad_fn, epsilon, L, J, H, alpha):\n",
    "    \"\"\"\n",
    "    X, P: (Q, n) arrays (Q = batch_samples * num_states)\n",
    "    grad_fn is called each step (your preference)\n",
    "    Returns new X, P; does not modify inputs in-place.\n",
    "    \"\"\"\n",
    "    Xn = X.copy()\n",
    "    Pn = P.copy()\n",
    "\n",
    "    # half-step momentum\n",
    "    Pn -= 0.5 * epsilon * grad_fn(Xn, J, H, alpha)\n",
    "\n",
    "    # L full steps\n",
    "    for k in range(L):\n",
    "        Xn += epsilon * Pn\n",
    "        if k != L - 1:\n",
    "            Pn -= epsilon * grad_fn(Xn, J, H, alpha)\n",
    "\n",
    "    # final half-step\n",
    "    Pn -= 0.5 * epsilon * grad_fn(Xn, J, H, alpha)\n",
    "    return Xn, Pn\n",
    "\n",
    "\n",
    "# --- Fully vectorized T-matrix builder (no loops over states/samples) ---\n",
    "def HMC_T_matrix_vectorized(problem_inst, epsilon=0.1, L=10, alpha=3.0,\n",
    "                            num_samples=100, num_p_samples=10,\n",
    "                            pairs_per_batch= 1 << 22,  # controls RAM; raise if you have more\n",
    "                            seed=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Vectorizes across ALL states and batched samples.\n",
    "    Only a short loop over batches (for memory) and over L (integrator time).\n",
    "    \"\"\"\n",
    "    rng   = np.random.default_rng(seed)\n",
    "    J     = np.ascontiguousarray(problem_inst.J_quantum, dtype=np.float64)\n",
    "    J     = (J + J.T)     # ensure symmetry\n",
    "    H     = np.asarray(problem_inst.h_quantum, dtype=np.float64)\n",
    "    n     = int(problem_inst.n)\n",
    "    beta  = float(problem_inst.T)\n",
    "\n",
    "    \n",
    "\n",
    "    m = 1 << n  # number of states\n",
    "\n",
    "    V0 = np.stack(all_configs(n), axis=0).astype(np.int8)        # (m, n)\n",
    "\n",
    "    # Map states to indices and initial energies (vectorized)\n",
    "    state_idx = spins_to_int(V0)               # (m,)\n",
    "    E_rev = np.asarray(problem_inst.E_arr[::-1], dtype=np.float64)  # (m,)\n",
    "    U_init_state = E_rev[state_idx]                       # (m,)\n",
    "\n",
    "    # Continuous x for each state (same magnitude, sign = spin)\n",
    "    c = np.arctanh(0.999) / alpha\n",
    "    X0 = (c * V0).astype(np.float64)                      # (m, n)\n",
    "\n",
    "    # Integer histogram: counts[row=dest_state, col=start_state]\n",
    "    counts = np.zeros((m, m), dtype=np.int32)\n",
    "\n",
    "    total_samples = int(num_samples) * int(num_p_samples)\n",
    "    samples_per_batch = max(1, pairs_per_batch // m)\n",
    "    if verbose:\n",
    "        print(f\"n={n}, m={m}, total_samples={total_samples}, \"\n",
    "              f\"samples_per_batch={samples_per_batch}, L={L}\")\n",
    "\n",
    "    processed = 0\n",
    "    i_cols = np.arange(m, dtype=np.int64)                 # (m,)\n",
    "\n",
    "    while processed < total_samples:\n",
    "        print(processed, '/', total_samples, ' ' , end='')\n",
    "        print('.', end='')\n",
    "        B = min(samples_per_batch, total_samples - processed)  # samples in this batch\n",
    "        Q = B * m\n",
    "\n",
    "        # Build flattened batch across ALL columns\n",
    "        X_flat = np.tile(X0, (B, 1))                      # (Q, n)\n",
    "        P_flat = rng.normal(size=(Q, n))                  # (Q, n)\n",
    "\n",
    "        # Initial Hamiltonian\n",
    "        K0 = 0.5 * np.einsum('ij,ij->i', P_flat, P_flat)  # (Q,)\n",
    "        col_idx_flat = np.tile(i_cols, B)                 # (Q,)\n",
    "        U0 = U_init_state[col_idx_flat]                   # (Q,)\n",
    "        H0 = K0 + U0\n",
    "\n",
    "        # Integrate (grad called inside leapfrog)\n",
    "        X1, P1 = leapfrog_integrator_batch(\n",
    "            X_flat, P_flat, grad_U, epsilon, L, J, H, alpha\n",
    "        )\n",
    "\n",
    "        # Final Hamiltonian\n",
    "        K1 = 0.5 * np.einsum('ij,ij->i', P1, P1)          # (Q,)\n",
    "\n",
    "        # Discretize: sign(tanh(alpha*X1)) for INDEXING ONLY\n",
    "        T1 = np.tanh(alpha * X1)\n",
    "        V1 = np.where(T1 >= 0.0, 1, -1).astype(np.int8)   # (Q, n)\n",
    "        j_flat = spins_to_int(V1)              # (Q,)\n",
    "\n",
    "        U1 = E_rev[j_flat]\n",
    "        H1 = K1 + U1\n",
    "\n",
    "        # Vectorized accept/reject\n",
    "        dH = H1 - H0\n",
    "        acc_prob = np.where(dH <= 0.0, 1.0, np.exp(-beta * dH))\n",
    "        accept = rng.random(Q) < acc_prob\n",
    "\n",
    "        dest_flat = np.where(accept, j_flat, col_idx_flat)\n",
    "\n",
    "        # Scatter-add into histogram\n",
    "        np.add.at(counts, (dest_flat, col_idx_flat), 1)\n",
    "\n",
    "        processed += B\n",
    "\n",
    "    # Probabilities per column\n",
    "    T = counts.astype(np.float64) / float(total_samples)\n",
    "    T = normalize_transition_matrix(T, eps=1e-12, verbose=verbose)\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cd806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ab041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b07976-4764-4884-b390-3a7a54221a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting problem instance 8 of 2000 with n = 10\n",
      "0 / 100000  .4096 / 100000  .8192 / 100000  .12288 / 100000  ."
     ]
    }
   ],
   "source": [
    "filepath = '/Users/vinit/Downloads/Research/Quantum-Sampling/Manas\\' Proposals/'\n",
    "filename_instances =  '/instances_new.pkl'\n",
    "sample_size=1000\n",
    "\n",
    "from tqdm import tqdm\n",
    "instances = pd.read_pickle(filepath + filename_instances)\n",
    "tot_instances = np.max(instances['Instance Number'].values)\n",
    "\n",
    "results = pd.DataFrame(columns = [\n",
    "    'Instance Number',\n",
    "    'Spins', \n",
    "    'Temperature', \n",
    "    'Connectivity',\n",
    "    'Proposal',\n",
    "    'Acceptance',\n",
    "#    'Mismatched',\n",
    "    'Gap',\n",
    "    'Gap Lazy'\n",
    "        ])\n",
    "# T_logmesh = np.logspace(-3, 3, 50)\n",
    "# T_round = np.sort( np.kron(np.array([1,5]), 10.**np.arange(-3,4)))\n",
    "# T_lim = np.array([0, np.inf]) \n",
    "# T_arr = np.unique( np.concatenate((T_logmesh, T_round, T_lim))) \n",
    "# T_arr = [1]\n",
    "delta_step = 0.2\n",
    "\n",
    "\n",
    "for instance_num in range(1, tot_instances+1):\n",
    "    instance_num = 8\n",
    "\n",
    "    cond  = (instances['Instance Number']==instance_num)\n",
    "    n            = instances[cond]['Spins'].values[0]\n",
    "    connectivity = instances[cond]['Connectivity'].values[0]\n",
    "    J            = instances[cond]['J'].values[0]    #np.triu(np.ones((n,n)),k=1) #\n",
    "    h            = instances[cond]['h'].values[0]\n",
    "\n",
    "    print('Starting problem instance', instance_num, 'of', tot_instances, 'with n =', n)\n",
    "\n",
    "    problem_inst = ProblemInstance(J, h)\n",
    "\n",
    "    T = 1\n",
    "    prop_type = 'Continuous-HMC'\n",
    "    accept_type = 'metropolis'\n",
    "\n",
    "\n",
    "    problem_inst.T = T\n",
    "\n",
    "    tm = time.time()\n",
    "    transition_mat_vec = HMC_T_matrix_vectorized(problem_inst, epsilon=0.2, L=10, alpha=3.0,\n",
    "                            num_samples=1000, num_p_samples=100)\n",
    "    print(\"Time for vectorized T-matrix:\", time.time() - tm)\n",
    "    # plt.imshow(transition_mat_vec)\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    transition_mat = HMC_T_matrix(problem_inst, epsilon=0.2, L=10, alpha=3.0, num_samples=1000, num_p_samples=100)\n",
    "    # plt.imshow(transition_mat)\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.imshow(np.abs(transition_mat - transition_mat_vec))\n",
    "    # plt.colorbar()\n",
    "\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "    gap, _ = abs_spectral_gap(transition_mat)\n",
    "\n",
    "    results_datum = {\n",
    "        'Instance Number': instance_num,\n",
    "        'Spins': n, \n",
    "        'Temperature': T, \n",
    "        'Connectivity': connectivity,\n",
    "        'Proposal': prop_type,\n",
    "        'Acceptance': accept_type,\n",
    "        'Mismatched': False,\n",
    "        'Gap': gap,\n",
    "        \"delta_time_step_Trotter\": delta_step\n",
    "    }\n",
    "\n",
    "\n",
    "    print(\"Instance {}, T = {}, Proposal = {}, Acceptance = {}, Gap = {:.4f}\".format(\n",
    "        instance_num, T, prop_type, accept_type, gap))\n",
    "    \n",
    "    results = pd.concat([results,pd.DataFrame([results_datum])], ignore_index=True)\n",
    "\n",
    "    \n",
    "    # #Sampling\n",
    "    # empirical_dist, key_list = Sampling_MCMC_trajectories(problem_inst, \n",
    "    #                                     Transition_matrix=transition_mat, sample_size=sample_size, burn=sample_size//10)\n",
    "\n",
    "    # fig, ax = plt.subplots(1, figsize=(7,4))\n",
    "    # if prop_type == 'quantum_time_mid_gamma_mid_Trotter':\n",
    "    #     prop_type = 'quantum_circ'\n",
    "    # ax.plot(empirical_dist, label=prop_type + ' n={}'.format(problem_inst.n))\n",
    "    # exact_dist = np.exp(-problem_inst.T*problem_inst.E_arr[::-1])\n",
    "    # exact_dist = exact_dist / np.sum(exact_dist)\n",
    "\n",
    "    # ax.plot(exact_dist, marker='o', linestyle='dashed', label='exact,  n={}'.format(problem_inst.n))\n",
    "    \n",
    "    # ax.set_xlabel(\"Configurations(s)\", fontsize=16)\n",
    "    # ax.set_ylabel(\"P(s)\", fontsize=16)\n",
    "    # ax.legend(loc='best', fontsize=12)\n",
    "    # ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    # plt.savefig(os.getcwd() + \"/Figures/{}_vs_configs_n_{}.png\".format(prop_type, problem_inst.n), bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "#results.to_pickle('results_new_all_prop.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5376fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c87941",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a68e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] grad_U vectorization\n"
     ]
    }
   ],
   "source": [
    "def test_grad_vectorization(J, h, alpha, n, Q=17, seed=0, atol=1e-12):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X  = rng.normal(size=(Q, n))\n",
    "    g1 = grad_U(X, J, h, alpha)                   # vectorized call\n",
    "    g2 = np.vstack([grad_U(x, J, h, alpha) for x in X])  # rowwise\n",
    "    assert np.allclose(g1, g2, atol=atol), np.max(np.abs(g1-g2))\n",
    "    print(\"[OK] grad_U vectorization\")\n",
    "\n",
    "n = problem_inst.n\n",
    "test_grad_vectorization(problem_inst.J_quantum, problem_inst.h_quantum, alpha=3.0, n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3d6e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] leapfrog scalar vs batch\n"
     ]
    }
   ],
   "source": [
    "def test_leapfrog_equivalence(J, h, alpha, n, epsilon=0.05, L=7, seed=1, Q=11, atol=1e-10):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X  = rng.normal(size=(Q, n))\n",
    "    P  = rng.normal(size=(Q, n))\n",
    "\n",
    "    # scalar loop (original)\n",
    "    Xs, Ps = [], []\n",
    "    for i in range(Q):\n",
    "        xi, pi = leapfrog_integrator(X[i], P[i], grad_U, epsilon, L, J, h, alpha)\n",
    "        Xs.append(xi); Ps.append(pi)\n",
    "    Xs = np.vstack(Xs); Ps = np.vstack(Ps)\n",
    "\n",
    "    # batch (vectorized)\n",
    "    Xb, Pb = leapfrog_integrator_batch(X, P, grad_U, epsilon, L, J, h, alpha)\n",
    "\n",
    "    assert np.allclose(Xs, Xb, atol=atol), np.max(np.abs(Xs-Xb))\n",
    "    assert np.allclose(Ps, Pb, atol=atol), np.max(np.abs(Ps-Pb))\n",
    "    print(\"[OK] leapfrog scalar vs batch\")\n",
    "\n",
    "test_leapfrog_equivalence(problem_inst.J_quantum, problem_inst.h_quantum, alpha=3.0, n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
